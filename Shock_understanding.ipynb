{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Module_Diagnostics.ipynb\n",
      "testing compute_RMS(...):\n",
      "This should be close to 1: 1.0094744220983753\n",
      "This should be close to 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "\n",
    "import pylab as pl\n",
    "import matplotlib\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from matplotlib.gridspec    import GridSpec\n",
    "import import_ipynb\n",
    "\n",
    "import Module_Diagnostics as MD\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "#Debugger. For some reason, using it inside a function works well. Otherwise...\n",
    "from IPython.core.debugger import set_trace\n",
    "#exemple: \n",
    "# def debug():\n",
    "#     set_trace()\n",
    "    \n",
    "#     `code_to_debug`\n",
    "    \n",
    "#     return\n",
    "\n",
    "# debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = [9.4, 4.8]\n",
    "# matplotlib.use('nbagg') #_comment this line if you don't need to interact with plots (zoom, translations, savings...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Choose run and time for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date of the simulation (DD_MM_YY): 18_08_20\n",
      "time dump (in 1/omega_ci): 00230\n"
     ]
    }
   ],
   "source": [
    "run_name = 'RUN_NAME'\n",
    "\n",
    "loop = False #LOOP #(LOOP is a boolean)\n",
    "time = 231 #TIME\n",
    "time = '%05d' % time    # Change the time to string format, needed by functions\n",
    "\n",
    "### Only for use:\n",
    "\n",
    "#if working on lx-moissard\n",
    "Cluster = 'Occ/'\n",
    "run_name = '20_08_18_new_big_one_0'\n",
    "# run_name = '20_09_07_start_big_one_2_bis'\n",
    "# run_name = \"20_05_18_event_only\"\n",
    "filepath = '/data/Lathys/Visualisation/' + Cluster + run_name + '/ncfiles/'\n",
    "\n",
    "#if working on occigene\n",
    "# filepath = '../ncfiles/'\n",
    "\n",
    "try:\n",
    "    date = re.search('Magw_(.+?)_t', glob.glob(filepath+'Magw*_t'+time+'.nc')[0]).group(1)\n",
    "except (IndexError, AttributeError): \n",
    "    sys.exit(f\"\"\"time_dump {time} does not appear to have data.\n",
    "             Let us go to the next time_dump\"\"\")\n",
    "\n",
    "print(f'date of the simulation (DD_MM_YY): {date}')\n",
    "print(f'time dump (in 1/omega_ci): {time}')\n",
    "\n",
    "#This is used by the functions find_ip_shock(N, V) and find_mc_leading_edge(B)\n",
    "metadata = {'t_shock_entrance' : 130,\n",
    "            't_shock_exit'     : 240,\n",
    "            't_MC_entrance'    : 130,\n",
    "            't_MC_exit'        : 270}\n",
    "#todo: autodefine t_collision? maybe from story_reader will be easier, as lines will cross on the multivariate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Prepare for plt.savefig\n",
    "storing_directory = filepath + \"../structure_images/\"\n",
    "path_png = Path(storing_directory)\n",
    "time_label = f\"t{time}\"\n",
    "if path_png.exists():\n",
    "    pass\n",
    "else:\n",
    "    path_png.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "storing_directory_json = filepath + \"../json_files/\"\n",
    "\n",
    "path_store_json = Path(storing_directory_json)\n",
    "\n",
    "if not(path_store_json.exists()):\n",
    "    os.system(f'mkdir {path_store_json}')\n",
    "\n",
    "name = \"sav_shock_understanding_\" + run_name + \".json\"\n",
    "path_json = Path(storing_directory_json + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#The next line links directly to my PhD_Manuscript on Overleaf.com\n",
    "#Saving plots there means that I do not need to worry about having the very last versions before\n",
    "#starting to write about it in Overleaf, since they will always be up-to-date.\n",
    "\n",
    "#IMPORTANT: for it to work, add the following line to ~/.bashrc\n",
    "#export DROPBOX=\"/home/moissard/Dropbox\" (to adapt to the particular machine)\n",
    "dropbox = os.environ['DROPBOX']\n",
    "dropbox_dir = dropbox + \"/Apps/Overleaf/PhD_Manuscript/Images/LATHYS/\"\n",
    "\n",
    "# plt.savefig(dropbox_dir + '/' + saving_title + run_name + \".png\",\n",
    "#             transparent=True, bbox_inches='tight', pad_inches=0.1)\n",
    "\n",
    "#If not working on the manuscript anymore, avoid changing images there by mistake\n",
    "dropbox_dir = storing_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load data to large 3D arrays: N, (Bx, By, Bz), _etc._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Clear /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing up /tmp/ ...\n",
      "Indeed by using memmap, this code creates heavy temporary files\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\"\"Clearing up /tmp/ ...\n",
    "Indeed by using memmap, this code creates heavy temporary files\"\"\")\n",
    "#Note: >/dev/null 2>&1 makes the system silent. Usually this command raises a lot of\n",
    "# 'Action not permitted'. But that's fine. Nothing to debug here. tmp/ is full of\n",
    "# files that should not be deleted, which are protected by root privileges.\n",
    "os.system('rm -rf /tmp/* >/dev/null 2>&1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Upload B, n, E, T, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Magw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading Bx...\n",
      "Reading By...\n",
      "Reading Bz...\n",
      "Close file and return...\n",
      "storing Magnetic field in a memmap\n",
      "deleting Magw to alleviate RAM\n",
      "Importing Elew 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading Ex...\n",
      "Reading Ey...\n",
      "Reading Ez...\n",
      "Close file and return...\n",
      "storing Electric field in a memmap\n",
      "deleting Elew to alleviate RAM\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "storing Plasma parameters in memmaps\n",
      "deleting Hsw to alleviate RAM\n"
     ]
    }
   ],
   "source": [
    "## Load B and X, Y, Z\n",
    "\n",
    "# There might be some MemoryError. In that case, follow the guide:\n",
    "# https://stackoverflow.com/questions/60563936/memoryerror-unable-to-allocate-3-78-gib-for-an-array-with-shape-802-842-1502\n",
    "Magw = MD.import_data_3D(filepath, date, time, 'Magw')\n",
    "\n",
    "cwp = Magw['c_omegapi'][0]\n",
    "gstep = Magw['gstep']\n",
    "r_planet = Magw['r_planet'][0]\n",
    "\n",
    "#Thomas Huret recommands shifting the axes so that the planet is indeed in (0,0,0)\n",
    "#It has got something to do with lists starting at 1 instead of 0 in Fortran...?\n",
    "X = np.array(np.around(Magw['x']))#+gstep[0]  \n",
    "Y = np.array(np.around(Magw['y']))#+gstep[1]\n",
    "Z = np.array(np.around(Magw['z']))#-gstep[1]\n",
    "\n",
    "nx,  ny,  nz  = len(X), len(Y), len(Z)\n",
    "# Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "# Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "nx0, ny0, nz0 = ( int(np.where(abs(X)==min(abs(X)))[0]),\n",
    "                  int(np.where(abs(Y)==min(abs(Y)))[0]), \n",
    "                  int(np.where(abs(Z)==min(abs(Z)))[0])  )\n",
    "            \n",
    "# Use memmap to alleviate RAM\n",
    "# This stores big arrays on the disk, but in a way that still allows for most\n",
    "# operations available on an np.array\n",
    "print(\"storing Magnetic field in a memmap\")\n",
    "file_Bx = path.join(mkdtemp(), 'Bx.dat')            \n",
    "Bx = np.memmap(file_Bx, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Bx[:] = Magw['Bx']\n",
    "file_By = path.join(mkdtemp(), 'By.dat')            \n",
    "By = np.memmap(file_By, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "By[:] = Magw['By']\n",
    "file_Bz = path.join(mkdtemp(), 'Bz.dat')            \n",
    "Bz = np.memmap(file_Bz, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Bz[:] = Magw['Bz']\n",
    "print(\"deleting Magw to alleviate RAM\")\n",
    "del Magw\n",
    "B = [Bx, By, Bz]\n",
    "\n",
    "## Load E\n",
    "# Electric field in mV/m\n",
    "Elew = MD.import_data_3D(filepath, date, time, 'Elew')\n",
    "print(\"storing Electric field in a memmap\")\n",
    "file_Ex = path.join(mkdtemp(), 'Ex.dat')            \n",
    "Ex = np.memmap(file_Ex, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ex[:] = Elew['Ex']*1e6\n",
    "file_Ey = path.join(mkdtemp(), 'Ey.dat')            \n",
    "Ey = np.memmap(file_Ey, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ey[:] = Elew['Ey']*1e6\n",
    "file_Ez = path.join(mkdtemp(), 'Ez.dat')            \n",
    "Ez = np.memmap(file_Ez, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ez[:] = Elew['Ez']*1e6\n",
    "print(\"deleting Elew to alleviate RAM\")\n",
    "del Elew\n",
    "E = [Ex, Ey, Ez]\n",
    "\n",
    "## Load N, Vxyz, and T\n",
    "Hsw = MD.import_data_3D(filepath, date, time, 'Hsw')\n",
    "print(\"storing Plasma parameters in memmaps\")\n",
    "# Density in nb/cm^3\n",
    "file_N = path.join(mkdtemp(), 'N.dat')            \n",
    "N = np.memmap(file_N, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "N[:] = Hsw['n']\n",
    "# Velocity in km/s\n",
    "file_Vx = path.join(mkdtemp(), 'Vx.dat')            \n",
    "Vx = np.memmap(file_Vx, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vx[:] = Hsw['Vx']\n",
    "file_Vy = path.join(mkdtemp(), 'Vy.dat')            \n",
    "Vy = np.memmap(file_Vy, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vy[:] = Hsw['Vy']\n",
    "file_Vz = path.join(mkdtemp(), 'Vz.dat')            \n",
    "Vz = np.memmap(file_Vz, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vz[:] = Hsw['Vz']\n",
    "# Temperature in eV\n",
    "file_T = path.join(mkdtemp(), 'T.dat')            \n",
    "T = np.memmap(file_T, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "T[:] = Hsw['T']\n",
    "print(\"deleting Hsw to alleviate RAM\")\n",
    "del Hsw\n",
    "V = [Vx, Vy, Vz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1502, 722, 662)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Bx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot global, interactive view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xmin = min(X)\n",
    "xmax = 3*abs(xmin)   #Most of the length in the x direction is used to give space for the sheath to form\n",
    "                     #It is not really interesting\n",
    "zoom = (xmin, xmax, min(Y), max(Y), min(Z), max(Z))\n",
    "# zoom = (-100, 70, -200, 200, -200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Make plot interactive\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MD.plot_colormap(N[:,:,nz0], f'Density at {time} in (xy)', r'N (cm$^{-3}$)', 'xy',\n",
    "                 loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label, zoom = zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position_shock_xy = plt.ginput(1, timeout = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MD.plot_colormap(N[:,ny0,:], f'Density at {time} in (xz)', r'N (cm$^{-3}$)', 'xz',\n",
    "                 loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label, zoom = zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "position_shock_xz = plt.ginput(1, timeout = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Simple geometry assumption: shock normal is along x. This is not completely true.\n",
    "# Should we do something about it? It's tough because we don't have that many grid cells to play with.\n",
    "\n",
    "def cubes(position_shock, plan):\n",
    "    \n",
    "    '''Defines two cubes: one on the left and one on the right side of\n",
    "       a point.'''\n",
    "    \n",
    "    distance = 10\n",
    "    size_cubes = 4 # Goals and poles. This will be a 3 by 3 cube.\n",
    "    \n",
    "    x_shock = position_shock[0]\n",
    "    if plan == 'xy':\n",
    "        y_shock = position_shock[1]\n",
    "        z_shock = 0\n",
    "    if plan == 'xz':\n",
    "        y_shock = 0\n",
    "        z_shcok = position_shock[1]\n",
    "    \n",
    "    center_cube = x_shock, y_shock, z_shock\n",
    "\n",
    "    cube_x_max = x_shock + size_cubes/2\n",
    "    cube_x_min = x_shock - size_cubes/2\n",
    "    cube_y_max = y_shock + size_cubes/2\n",
    "    cube_y_min = y_shock - size_cubes/2\n",
    "    cube_z_max = z_shock + size_cubes/2\n",
    "    cube_z_min = z_shock - size_cubes/2\n",
    "\n",
    "    ix_min_left = int(np.where(cube_x_min + distance <=X)[0][0])    \n",
    "    ix_max_left = int(np.where(cube_x_max + distance <=X)[0][0])\n",
    "    ix_min_left = int(np.where(cube_x_min + distance <=X)[0][0])    \n",
    "    ix_max_left = int(np.where(cube_x_max + distance <=X)[0][0])\n",
    "    iy_min = int(np.where(cube_y_min<=Y)[0][0])\n",
    "    iy_max = int(np.where(cube_y_max<=Y)[0][0])\n",
    "    iz_min = int(np.where(cube_z_min<=Z)[0][0])\n",
    "    iz_max = int(np.where(cube_z_max<=Z)[0][0])\n",
    "    \n",
    "    cubes = {\n",
    "             'left':  (ix_min_left , ix_max_left , iy_min, iy_max, iz_min, iz_max) ,\n",
    "             'right': (ix_min_right, ix_max_right, iy_min, iy_max, iz_min, iz_max) ,\n",
    "             }\n",
    "    \n",
    "    return cubes\n",
    "\n",
    "def function_data_in_cube(data1, data2=None, function1=MD.identity, function_both=None, cube):\n",
    "    \n",
    "    '''\n",
    "    Returns the mean value of data in the different cubes.\n",
    "    If data is a vector (len(data)==3), then the function returns the mean value the norm(data[cubes])\n",
    "    '''\n",
    "    \n",
    "                    \n",
    "    ixmax, ixmin, iymax, iymin, izmax, izmin = cube                                                                      boxes[box][\"coord_magnetopause\"])\n",
    "        \n",
    "    slices = (slice(ixmin, ixmax), slice(iymin, iymax), slice(izmin, izmax))\n",
    "        \n",
    "    if (not(data2)):                       \n",
    "        result = function1( data1, slices )\n",
    "            \n",
    "    else:\n",
    "        result = function_both( function1( data1, slices ), [data2[0][slices],\n",
    "                                                             data2[1][slices],\n",
    "                                                             data2[2][slices]] )\n",
    "    data_in_cube = []        \n",
    "        if (len(result) == 3):\n",
    "            data_in_boxes.append( (np.mean(result[0]), np.mean(result[1]), np.mean(result[2])) )\n",
    "        else:\n",
    "            data_in_boxes.append( np.mean(result) )\n",
    "                  \n",
    "        \n",
    "\n",
    "    return data_in_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data in cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating J\n"
     ]
    }
   ],
   "source": [
    "cubes_xy = cubes(position_shock_xy, 'xy')\n",
    "cubes_xz = cubes(position_shock_xz, 'xz')\n",
    "\n",
    "B_xy_left  = function_data_in_cube(B, function1=MD.norm, cubes_xy['left' ])\n",
    "B_xy_right = function_data_in_cube(B, function1=MD.norm, cubes_xy['right'])\n",
    "\n",
    "B_xz_left  = function_data_in_cube(B, function1=MD.norm, cubes_xz['left' ])\n",
    "B_xz_right = function_data_in_cube(B, function1=MD.norm, cubes_xz['right'])\n",
    "\n",
    "B_vec_xy_left  = function_data_in_cube(B, cubes_xy['left' ])\n",
    "B_vec_xz_left  = function_data_in_cube(B, cubes_xz['left' ])\n",
    "\n",
    "B_vec_xy_right = function_data_in_cube(B, cubes_xy['right'])\n",
    "B_vec_xz_right = function_data_in_cube(B, cubes_xz['right'])\n",
    "\n",
    "N_upstream, N_nose, N_yup, N_ydown, N_zup, N_zdown = MD.compute_data_in_cubes(N)\n",
    "\n",
    "T_upstream, T_nose, T_yup, T_ydown, T_zup, T_zdown = MD.compute_data_in_cubes(T)\n",
    "\n",
    "V_upstream, V_nose, V_yup, V_ydown, V_zup, V_zdown = MD.compute_data_in_cubes(V, function1=MD.norm)\n",
    "\n",
    "Vx_upstream, Vx_nose, Vx_yup, Vx_ydown, Vx_zup, Vx_zdown = MD.compute_data_in_cubes(Vx)\n",
    "Vy_upstream, Vy_nose, Vy_yup, Vy_ydown, Vy_zup, Vy_zdown = MD.compute_data_in_cubes(Vy)\n",
    "Vz_upstream, Vz_nose, Vz_yup, Vz_ydown, Vz_zup, Vz_zdown = MD.compute_data_in_cubes(Vz)\n",
    "\n",
    "print(\"calculating J\")\n",
    "J_upstream, J_nose, J_yup, J_ydown, J_zup, J_zdown = MD.compute_data_in_cubes(data1=B, function1=MD.J)\n",
    "\n",
    "Jx_upstream, Jx_nose, Jx_yup, Jx_ydown, Jx_zup, Jx_zdown = MD.compute_data_in_cubes(B, function1=MD.Jx)\n",
    "Jy_upstream, Jy_nose, Jy_yup, Jy_ydown, Jy_zup, Jy_zdown = MD.compute_data_in_cubes(B, function1=MD.Jy)\n",
    "Jz_upstream, Jz_nose, Jz_yup, Jz_ydown, Jz_zup, Jz_zdown = MD.compute_data_in_cubes(B, function1=MD.Jz)\n",
    "\n",
    "JE_upstream, JE_nose, JE_yup, JE_ydown, JE_zup, JE_zdown = MD.compute_data_in_cubes(data1=B, data2=E,\n",
    "                                                                                    function1=MD.J,\n",
    "                                                                                    function_both=MD.dot_product)\n",
    "\n",
    "\n",
    "JxB_upstream, JxB_nose, JxB_yup, JxB_ydown, JxB_zup, JxB_zdown = MD.compute_data_in_cubes(data1=B, data2=B,\n",
    "                                                                                          function1=MD.J,\n",
    "                                                                                          function_both=MD.cross_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_xy_left  = function_data_in_cube(E, function1=MD.norm, cubes_xy['left' ])\n",
    "E_xy_right = function_data_in_cube(E, function1=MD.norm, cubes_xy['right'])\n",
    "\n",
    "E_xz_left  = function_data_in_cube(E, function1=MD.norm, cubes_xz['left' ])\n",
    "E_xz_right = function_data_in_cube(E, function1=MD.norm, cubes_xz['right'])\n",
    "\n",
    "E_vec_xy_left  = function_data_in_cube(E, cubes_xy['left'])\n",
    "E_vec_xz_left  = function_data_in_cube(E, cubes_xz['left'])\n",
    "\n",
    "E_vec_xy_right = function_data_in_cube(E, cubes_xy['right'])\n",
    "E_vec_xz_right = function_data_in_cube(E, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_xy_left  = function_data_in_cube(V, function1=MD.norm, cubes_xy['left' ])\n",
    "V_xy_right = function_data_in_cube(V, function1=MD.norm, cubes_xy['right'])\n",
    "\n",
    "V_xz_left  = function_data_in_cube(V, function1=MD.norm, cubes_xz['left' ])\n",
    "V_xz_right = function_data_in_cube(V, function1=MD.norm, cubes_xz['right'])\n",
    "\n",
    "V_vec_xy_left  = function_data_in_cube(V, cubes_xy['left'])\n",
    "V_vec_xz_left  = function_data_in_cube(V, cubes_xz['left'])\n",
    "\n",
    "V_vec_xy_right = function_data_in_cube(V, cubes_xy['right'])\n",
    "V_vec_xz_right = function_data_in_cube(V, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_vec_xy_left  = function_data_in_cube(N, cubes_xy['left' ])\n",
    "N_vec_xz_left  = function_data_in_cube(N, cubes_xz['left' ])\n",
    "\n",
    "N_vec_xy_right = function_data_in_cube(N, cubes_xy['right'])\n",
    "N_vec_xz_right = function_data_in_cube(N, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_vec_xy_left  = function_data_in_cube(T, cubes_xy['left' ])\n",
    "T_vec_xz_left  = function_data_in_cube(T, cubes_xz['left' ])\n",
    "\n",
    "T_vec_xy_right = function_data_in_cube(T, cubes_xy['right'])\n",
    "T_vec_xz_right = function_data_in_cube(T, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_xy_left = function_data_in_cube(B, function1=MD.J, cubes_xy['left'])\n",
    "J_xz_left = function_data_in_cube(B, function1=MD.J, cubes_xz['left'])\n",
    "\n",
    "J_xy_right = function_data_in_cube(B, function1=MD.J, cubes_xy['right'])\n",
    "J_xz_right = function_data_in_cube(B, function1=MD.J, cubes_xz['right'])\n",
    "\n",
    "Jx_xy_left = function_data_in_cube(B, function1=MD.Jx, cubes_xy['left'])\n",
    "Jx_xz_left = function_data_in_cube(B, function1=MD.Jx, cubes_xz['left'])\n",
    "\n",
    "Jx_xy_right = function_data_in_cube(B, function1=MD.Jx, cubes_xy['right'])\n",
    "Jx_xz_right = function_data_in_cube(B, function1=MD.Jx, cubes_xz['right'])\n",
    "\n",
    "Jy_xy_left = function_data_in_cube(B, function1=MD.Jy, cubes_xy['left'])\n",
    "Jy_xz_left = function_data_in_cube(B, function1=MD.Jy, cubes_xz['left'])\n",
    "\n",
    "Jy_xy_right = function_data_in_cube(B, function1=MD.Jy, cubes_xy['right'])\n",
    "Jy_xz_right = function_data_in_cube(B, function1=MD.Jy, cubes_xz['right'])\n",
    "\n",
    "Jz_xy_left = function_data_in_cube(B, function1=MD.Jz, cubes_xy['left'])\n",
    "Jz_xz_left = function_data_in_cube(B, function1=MD.Jz, cubes_xz['left'])\n",
    "\n",
    "Jz_xy_right = function_data_in_cube(B, function1=MD.Jz, cubes_xy['right'])\n",
    "Jz_xz_right = function_data_in_cube(B, function1=MD.Jz, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conversion to SI:\n",
    "b = 1e-9\n",
    "n = 1e6\n",
    "v = 1e3\n",
    "t = 11605\n",
    "#put pressure in nPa\n",
    "p = 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pmag_xy_left = function_data_in_cube(p*(b*MD.norm(B))**2/(2*MD.µ0), cubes_xy['left'])\n",
    "Pmag_xz_left = function_data_in_cube(p*(b*MD.norm(B))**2/(2*MD.µ0), cubes_xz['left'])\n",
    "\n",
    "Pmag_xy_right = function_data_in_cube(p*(b*MD.norm(B))**2/(2*MD.µ0), cubes_xy['right'])\n",
    "Pmag_xz_right = function_data_in_cube(p*(b*MD.norm(B))**2/(2*MD.µ0), cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pdyn_xy_left = function_data_in_cube(p*(1./2)*MD.mp*(n*N)*(v*MD.norm(V))**2, cubes_xy['left'])\n",
    "Pdyn_xz_left = function_data_in_cube(p*(1./2)*MD.mp*(n*N)*(v*MD.norm(V))**2, cubes_xz['left'])\n",
    "\n",
    "Pdyn_xy_right = function_data_in_cube(p*(1./2)*MD.mp*(n*N)*(v*MD.norm(V))**2, cubes_xy['right'])\n",
    "Pdyn_xz_right = function_data_in_cube(p*(1./2)*MD.mp*(n*N)*(v*MD.norm(V))**2, cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pth_xy_left = function_data_in_cube(p*MD.kB*(n*N)*(t*T), cubes_xy['left'])\n",
    "Pth_xz_left = function_data_in_cube(p*MD.kB*(n*N)*(t*T), cubes_xz['left'])\n",
    "\n",
    "Pth_xy_right = function_data_in_cube(p*MD.kB*(n*N)*(t*T), cubes_xy['right'])\n",
    "Pth_xz_right = function_data_in_cube(p*MD.kB*(n*N)*(t*T), cubes_xz['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_xy_left = B_xy_left / (MD.µ0 * MD.mp * N_xy_left)\n",
    "\n",
    "va_test_1 = VA_xy_left\n",
    "va_test_2 = np.sqrt(Pmag_xy_left / (MD.mp * N_xy_left)\n",
    "n = 3\n",
    "assert isclose(va_test_1, va_test_2, abs_tol=10**-n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_xy_left = B_xy_left / (MD.µ0 * MD.mp * N_xy_left)\n",
    "VA_xz_left = B_xy_left / (MD.µ0 * MD.mp * N_xz_left)\n",
    "\n",
    "VA_xy_right = B_xy_right / (MD.µ0 * MD.mp * N_xy_right)\n",
    "VA_xz_right = B_xy_right / (MD.µ0 * MD.mp * N_xz_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V_shock higher in (xz) than (xy) $$v_s = \\frac{n_1 v_1 - n_2 v_2}{n_1 - n_2}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs_xy = (N_xy_left * V_xy_left - N_xy_right * V_xy_right) / (N_xy_left - N_xy_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs_xz = (N_xz_left * V_xz_left - N_xz_right * V_xz_right) / (N_xz_left - N_xz_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vs_xz > Vs_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis: $$v_A^{xy} > v_A^{xz} \\implies M_{A (shock)}^{xy} < M_{A (shock)}^{xz} \\implies T_{down}^{xy} < T_{down}^{xz} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VA_xy_right > VA_xz_right "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Ashock_xy = Vs_xy / VA_xy_right\n",
    "M_Ashock_xz = Vs_xz / VA_xz_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_Ashock_xy < M_Ashock_xz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'T_xy_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4ba8070283a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT_xy_left\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mT_xz_left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'T_xy_left' is not defined"
     ]
    }
   ],
   "source": [
    "T_xy_left < T_xz_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store relevant data for the current time dump"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
