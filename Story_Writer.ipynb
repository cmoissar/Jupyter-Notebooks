{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Module_Diagnostics.ipynb\n",
      "testing compute_RMS(...):\n",
      "This should be close to 1: 1.0107479333806364\n",
      "This should be close to 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pylab as pl\n",
    "import matplotlib\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from matplotlib.gridspec    import GridSpec\n",
    "import import_ipynb\n",
    "\n",
    "import Module_Diagnostics as MD\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "#Debugger. For some reason, using it inside a function works well. Otherwise...\n",
    "from IPython.core.debugger import set_trace\n",
    "#exemple: \n",
    "# def debug():\n",
    "#     set_trace()\n",
    "    \n",
    "#     `code_to_debug`\n",
    "    \n",
    "#     return\n",
    "\n",
    "# debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = [9.4, 4.8]\n",
    "# matplotlib.use('nbagg') #_comment this line if you don't need to interact with plots (zoom, translations, savings...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose run and time for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-3-6c680975956f>\", line 17, in <module>\n",
      "    date = re.search('Magw_(.+?)_t', glob.glob(filepath+'Magw*_t'+time+'.nc')[0]).group(1)\n",
      "IndexError: list index out of range\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clement/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-6c680975956f>\", line 20, in <module>\n",
      "    Let us go to the next time_dump\"\"\")\n",
      "SystemExit: time_dump 00223 does not appear to have data.\n",
      "             Let us go to the next time_dump\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clement/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/clement/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/clement/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6c680975956f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Magw_(.+?)_t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Magw*_t'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.nc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6c680975956f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     sys.exit(f\"\"\"time_dump {time} does not appear to have data.\n\u001b[0;32m---> 20\u001b[0;31m              Let us go to the next time_dump\"\"\")\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: time_dump 00223 does not appear to have data.\n             Let us go to the next time_dump",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2036\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m   2037\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0;32m-> 2038\u001b[0;31m                                                                      value))\n\u001b[0m\u001b[1;32m   2039\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m         \"\"\"\n\u001b[0;32m--> 823\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[1;32m    701\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                 + out_list)\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "run_name = 'RUN_NAME'\n",
    "\n",
    "loop = False #LOOP #(LOOP is a boolean)\n",
    "time = 223 #TIME\n",
    "time = '%05d' % time    # Change the time to string format, needed by functions\n",
    "\n",
    "### Only for use\n",
    "Cluster = 'Occ/'\n",
    "run_name = '20_08_18_new_big_one_0'\n",
    "\n",
    "#if working on lx-moissard\n",
    "filepath = '/data/Lathys/Visualisation/' + Cluster + run_name + '/ncfiles/'\n",
    "#if working on occigene\n",
    "# filepath = '../ncfiles/'\n",
    "\n",
    "try:\n",
    "    date = re.search('Magw_(.+?)_t', glob.glob(filepath+'Magw*_t'+time+'.nc')[0]).group(1)\n",
    "except (IndexError, AttributeError): \n",
    "    sys.exit(f\"\"\"time_dump {time} does not appear to have data.\n",
    "             Let us go to the next time_dump\"\"\")\n",
    "\n",
    "print(f'date of the simulation (DD_MM_YY): {date}')\n",
    "print(f'time dump (in 1/omega_ci): {time}')\n",
    "\n",
    "#This is used by the functions find_ip_shock(N, V) and find_mc_leading_edge(B)\n",
    "metadata = {'t_shock_entrance' : 130,\n",
    "            't_shock_exit'     : 240,\n",
    "            't_MC_entrance'    : 130,\n",
    "            't_MC_exit'        : 270}\n",
    "#todo: autodefine t_collision? maybe from story_reader will be easier, as lines will cross on the multivariate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plt.savefig\n",
    "storing_directory = filepath + \"../structure_images/\"\n",
    "path_png = Path(storing_directory)\n",
    "time_label = f\"t{time}\"\n",
    "if path_png.exists():\n",
    "    pass\n",
    "else:\n",
    "    path_png.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storing_directory_json = filepath + \"../json_files/\"\n",
    "\n",
    "path_store_json = Path(storing_directory_json)\n",
    "\n",
    "if not(path_store_json.exists()):\n",
    "    os.system(f'mkdir {path_store_json}')\n",
    "\n",
    "name = \"story_\" + run_name + \".json\"\n",
    "path_json = Path(storing_directory_json + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Get data in Hsw, Magw and Elew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Clear /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"\"\"Clearing up /tmp/ ...\n",
    "Indeed by using memmap, this code creates heavy temporary files\"\"\")\n",
    "#Note: >/dev/null 2>&1 makes the system silent. Usually this command raises a lot of\n",
    "# 'Action not permitted'. But that's fine. Nothing to debug here. tmp/ is full of\n",
    "# files that should not be deleted, which are protected by root privileges.\n",
    "os.system('rm -rf /tmp/* >/dev/null 2>&1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Upload B, n, E, T, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Load B and X, Y, Z\n",
    "\n",
    "# There might be some MemoryError. In that case, follow the guide:\n",
    "# https://stackoverflow.com/questions/60563936/memoryerror-unable-to-allocate-3-78-gib-for-an-array-with-shape-802-842-1502\n",
    "Magw = MD.import_data_3D(filepath, date, time, 'Magw')\n",
    "\n",
    "x = np.array(np.around(Magw['x']))\n",
    "y = np.array(np.around(Magw['y']))\n",
    "z = np.array(np.around(Magw['z']))\n",
    "\n",
    "cwp = Magw['c_omegapi']\n",
    "gstep = Magw['gstep']\n",
    "\n",
    "nx,  ny,  nz  = len(x), len(y), len(z)\n",
    "# Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "# Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "nx0, ny0, nz0 = ( int(np.where(abs(x)==min(abs(x)))[0]),\n",
    "                  int(np.where(abs(y)==min(abs(y)))[0]), \n",
    "                  int(np.where(abs(z)==min(abs(z)))[0])  )\n",
    "            \n",
    "# Use memmap to alleviate RAM\n",
    "# This stores big arrays on the disk, but in a way that still allows for most\n",
    "# operations available on an np.array\n",
    "print(\"storing Magnetic field in a memmap\")\n",
    "file_Bx = path.join(mkdtemp(), 'Bx.dat')            \n",
    "Bx = np.memmap(file_Bx, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Bx[:] = Magw['Bx']\n",
    "file_By = path.join(mkdtemp(), 'By.dat')            \n",
    "By = np.memmap(file_By, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "By[:] = Magw['By']\n",
    "file_Bz = path.join(mkdtemp(), 'Bz.dat')            \n",
    "Bz = np.memmap(file_Bz, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Bz[:] = Magw['Bz']\n",
    "print(\"deleting Magw to alleviate RAM\")\n",
    "del Magw\n",
    "B = [Bx, By, Bz]\n",
    "\n",
    "## Load E\n",
    "# Electric field in mV/m\n",
    "Elew = MD.import_data_3D(filepath, date, time, 'Elew')\n",
    "print(\"storing Electric field in a memmap\")\n",
    "file_Ex = path.join(mkdtemp(), 'Ex.dat')            \n",
    "Ex = np.memmap(file_Ex, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ex[:] = Elew['Ex']*1e6\n",
    "file_Ey = path.join(mkdtemp(), 'Ey.dat')            \n",
    "Ey = np.memmap(file_Ey, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ey[:] = Elew['Ey']*1e6\n",
    "file_Ez = path.join(mkdtemp(), 'Ez.dat')            \n",
    "Ez = np.memmap(file_Ez, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Ez[:] = Elew['Ez']*1e6\n",
    "print(\"deleting Elew to alleviate RAM\")\n",
    "del Elew\n",
    "E = [Ex, Ey, Ez]\n",
    "\n",
    "## Load N, Vxyz, and T\n",
    "Hsw = MD.import_data_3D(filepath, date, time, 'Hsw')\n",
    "print(\"storing Plasma parameters in memmaps\")\n",
    "# Density in nb/cm^3\n",
    "file_N = path.join(mkdtemp(), 'N.dat')            \n",
    "N = np.memmap(file_N, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "N[:] = Hsw['n']\n",
    "# Velocity in km/s\n",
    "file_Vx = path.join(mkdtemp(), 'Vx.dat')            \n",
    "Vx = np.memmap(file_Vx, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vx[:] = Hsw['Vx']\n",
    "file_Vy = path.join(mkdtemp(), 'Vy.dat')            \n",
    "Vy = np.memmap(file_Vy, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vy[:] = Hsw['Vy']\n",
    "file_Vz = path.join(mkdtemp(), 'Vz.dat')            \n",
    "Vz = np.memmap(file_Vz, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "Vz[:] = Hsw['Vz']\n",
    "# Temperature in eV\n",
    "file_T = path.join(mkdtemp(), 'T.dat')            \n",
    "T = np.memmap(file_T, dtype='float32', mode='w+', shape=(nx,ny,nz))\n",
    "T[:] = Hsw['T']\n",
    "print(\"deleting Hsw to alleviate RAM\")\n",
    "del Hsw\n",
    "V = [Vx, Vy, Vz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(gstep)\n",
    "for coord in x, y, z:\n",
    "    gstep_coord = np.mean(coord[1:] - coord[:-1])\n",
    "    print(gstep_coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.shape(Bx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot global view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Define IndexTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class IndexTracker(object):\n",
    "\n",
    "#     import pdb; pdb.set_trace()\n",
    "    \n",
    "    global fontsize\n",
    "    fontsize = 16\n",
    "\n",
    "    def __init__(self, ax, X, plane):\n",
    "        global plan\n",
    "        plan = plane\n",
    "\n",
    "        self.ax = ax\n",
    "        self.X = X\n",
    "\n",
    "        if plan=='xy':\n",
    "            rows, cols, self.slices = X.shape\n",
    "            self.ind = self.slices//2\n",
    "            self.im = ax.imshow(self.X[:, :, self.ind])\n",
    "        if plan=='xz':\n",
    "            rows, self.slices, cols = X.shape\n",
    "            self.ind = self.slices//2\n",
    "            self.im = ax.imshow(self.X[:, self.ind, :])\n",
    "        if plan=='yz':\n",
    "            self.slices, rows, cols = X.shape\n",
    "            self.ind = self.slices//2\n",
    "            self.im = ax.imshow(self.X[self.ind, :, :])\n",
    "\n",
    "        min_value = int(np.min(X))\n",
    "        max_value = int(np.median(X[np.isfinite(X)])*5)   \n",
    "        # Number of color levels\n",
    "        levels = MaxNLocator(nbins=255).tick_values(min_value, max_value)\n",
    "        nb_ticks = 10\n",
    "        cbar_ticks = MaxNLocator(nbins=nb_ticks).tick_values(min_value, max_value)\n",
    "        cbar_ticks = ['{:.0f}'.format(tick) for tick in cbar_ticks]\n",
    "        while ( len(cbar_ticks) <= nb_ticks ) :\n",
    "            cbar_ticks.append(r\"$\\infty$\")\n",
    "        cmap = plt.get_cmap('plasma')\n",
    "        norm = BoundaryNorm(levels, ncolors=cmap.N, clip=False)\n",
    "        # create an axes on the right side of ax. The width of cax will be 5%\n",
    "        # of ax and the padding between cax and ax will be fixed at 0.05 inch.\n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "\n",
    "        cbar = self.im.axes.figure.colorbar(self.im, cax=cax, cmap=cmap, norm=norm)\n",
    "        cbar.ax.set_yticklabels(cbar_ticks) #, fontsize=16, weight='bold')\n",
    "\n",
    "        self.update(ax)\n",
    "\n",
    "    def onscroll(self, event):\n",
    "        print(\"%s %s\" % (event.button, event.step))\n",
    "        if event.button == 'up':\n",
    "            self.ind = (self.ind + 1) % self.slices\n",
    "        else:\n",
    "            self.ind = (self.ind - 1) % self.slices\n",
    "        self.update(ax)\n",
    "\n",
    "    def update(self, ax):\n",
    "        if plan=='xy':\n",
    "            self.im.set_data(self.X[:, :, self.ind])\n",
    "            ax.set_title(f'''Use scroll wheel to navigate images. Display of plane ({plan}).\n",
    "z = {self.ind}''')\n",
    "            ax.set_ylabel('x', weight='bold', fontsize=fontsize)\n",
    "            ax.set_xlabel('y', weight='bold', fontsize=fontsize)\n",
    "        if plan=='xz':\n",
    "            self.im.set_data(self.X[:, self.ind, :])\n",
    "            ax.set_title(f'''Use scroll wheel to navigate images. Display of plane ({plan}).\n",
    "y = {self.ind}''')\n",
    "            ax.set_ylabel('x', weight='bold', fontsize=fontsize)\n",
    "            ax.set_xlabel('z', weight='bold', fontsize=fontsize)\n",
    "        if plan=='yz':\n",
    "            self.im.set_data(self.X[self.ind, :, :])\n",
    "            ax.set_title(f'''Use scroll wheel to navigate images. Display of plane ({plan}).\n",
    "x = {self.ind}''')\n",
    "            ax.set_ylabel('y', weight='bold', fontsize=fontsize)\n",
    "            ax.set_xlabel('z', weight='bold', fontsize=fontsize)\n",
    "        self.im.axes.figure.canvas.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tests cells (if bow shock or magnetopause are misplaced, this should help to understand the problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### bow_shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# When the bow_shock is misplaced, these next few cells should help understand why\n",
    "dl = 5\n",
    "\n",
    "str_coord='X'\n",
    "\n",
    "\n",
    "if (str_coord=='X'):\n",
    "    coord = x\n",
    "    slice_x = slice(None)\n",
    "    slice_y = slice(ny0-dl, ny0+dl)\n",
    "    slice_z = slice(nz0-dl, nz0+dl)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    #Values for x are higher, because the shock takes the solar wind head-on\n",
    "    #Dividing b_slice by 2 allows to use the same test for all coords.\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(1, 2))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(1, 2))/2\n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(1, 2))/2\n",
    "    n_slice = N[slices].mean(axis=(1, 2))\n",
    "\n",
    "if (str_coord=='Y'):\n",
    "    coord = y\n",
    "    gstep_coord = abs(np.mean(coord[1:] - coord[:-1]))\n",
    "    slice_x = slice(nx0-dl, nx0+dl)\n",
    "    slice_y = slice(None)\n",
    "    slice_z = slice(nz0-dl, nz0+dl)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(0, 2))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(0, 2))\n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(0, 2))\n",
    "    n_slice = N[slices].mean(axis=(0, 2))\n",
    "\n",
    "if (str_coord=='Z'):\n",
    "    coord = z\n",
    "    gstep_coord = abs(np.mean(coord[1:] - coord[:-1]))\n",
    "    slice_x = slice(nx0-dl, nx0+dl)\n",
    "    slice_y = slice(ny0-dl, ny0+dl)\n",
    "    slice_z = slice(None)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(0, 1))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(0, 1))\n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(0, 1))\n",
    "    n_slice = N[slices].mean(axis=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#general tests for magnetosheath:\n",
    "test_j_large   = j_slice > 1.7*np.median(j_slice)\n",
    "test_close_to_planet = (abs(coord)<min((1./2)*len(coord)*np.mean(coord[1:]-coord[:-1])\n",
    "                                               for coord in [x,y,z])-15)\n",
    "\n",
    "test_coord_up   = (coord > 0)\n",
    "test_coord_down = (coord < 0)\n",
    "\n",
    "test_up =    (  test_j_large\n",
    "              & test_close_to_planet\n",
    "              & test_coord_up        )\n",
    "\n",
    "\n",
    "from scipy import signal\n",
    "maximums = signal.argrelextrema(j_slice, np.greater, order=1+int(5/np.mean(gstep.data)))\n",
    "\n",
    "#This is need to discrimitate between\n",
    "#the bow shock and the interplanetary shock\n",
    "if str_coord=='X':\n",
    "    b_slice = savgol_filter(b_slice, 51, 3)\n",
    "    test_b_grad_up = (np.gradient(b_slice) < -0.5 )\n",
    "    test_up = test_up & test_b_grad_up\n",
    "\n",
    "\n",
    "test_down =  (  test_j_large\n",
    "              & test_close_to_planet\n",
    "              & test_coord_down      )\n",
    "\n",
    "def def_coord_bow_shock(test, loc='down'):\n",
    "\n",
    "    where_test = MD.aplatir(np.where(test))\n",
    "\n",
    "    if loc=='up':\n",
    "        where_test.reverse()\n",
    "\n",
    "    for t in where_test:\n",
    "        for local_max in j_slice[maximums]:\n",
    "#             print(f\"Comparing {j_slice[t]} with {local_max}, which yields {j_slice[t] == local_max}\")\n",
    "#             import time\n",
    "#             time.sleep(0.5)\n",
    "            if j_slice[t] == local_max:\n",
    "                return coord[t]\n",
    "    print(\"There is still some work to be done on bow shock detection\")\n",
    "    return 0\n",
    "\n",
    "coord_bow_shock_up   = def_coord_bow_shock(test_up, 'up')    \n",
    "coord_bow_shock_down = def_coord_bow_shock(test_down)\n",
    "\n",
    "if not(loop):\n",
    "    if str_coord == 'X':\n",
    "        entry = 'x_bow_shock'\n",
    "        absurdity = MD.check_for_absurdities(path_json, entry, time, coord_bow_shock_up)\n",
    "        print(absurdity)\n",
    "    if (str_coord == 'Y' or str_coord == 'Z'):\n",
    "        entry = str_coord.lower() + '_bow_shock_up'\n",
    "        absurdity = MD.check_for_absurdities(path_json, entry, time, coord_bow_shock_up)\n",
    "        print(absurdity)\n",
    "        entry = str_coord.lower() + '_bow_shock_down'\n",
    "        absurdity = MD.check_for_absurdities(path_json, entry, time, coord_bow_shock_down)\n",
    "        print(absurdity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.gridspec    import GridSpec\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10, 18))\n",
    "gs = GridSpec(6, 1)\n",
    "\n",
    "axe = plt.subplot(gs[0])\n",
    "axe.plot(coord, b_slice/150, label='b slice')\n",
    "axe.plot(coord, np.gradient(b_slice), label='gradient b')\n",
    "axe.plot(coord, test_up, label='test up')\n",
    "axe.plot(coord, test_down, label='test down')\n",
    "axe.set_ylim([-1.5,1.5])\n",
    "axe.axvline(coord_bow_shock_up   , color='red', label=\"bow shock up\")\n",
    "axe.axvline(coord_bow_shock_down , color='red', label=\"bow shock down\")\n",
    "axe.set_xlim([min(coord), abs(min(coord))])\n",
    "if str_coord == 'X':\n",
    "    axe.set_xlim([min(coord), 200])\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[1], sharex=axe)\n",
    "axe.plot(coord, j_slice , label='j')\n",
    "plt.scatter(coord[maximums], j_slice[maximums], label='local maximas')\n",
    "axe.set_ylim([-1,8*np.mean(j_slice)])\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[2], sharex=axe)\n",
    "axe.plot(coord, 1.4*test_up, label='testup', linewidth=6)\n",
    "axe.plot(coord, 1.0*test_j_large         , label='j large')\n",
    "axe.plot(coord, 1.1*test_close_to_planet , label='close to planet')\n",
    "if str_coord == 'X':\n",
    "    axe.plot(coord, 1.25*test_b_grad_up       , label='b grad up')\n",
    "axe.plot(coord, 1.3*test_coord_up        , label='coord up')\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[3], sharex=axe)\n",
    "axe.plot(coord, 1.4*test_down, label='testdown', linewidth=6)\n",
    "axe.plot(coord, 1.0*test_j_large         , label='j large')\n",
    "axe.plot(coord, 1.1*test_close_to_planet , label='close to planet')\n",
    "axe.plot(coord, 1.3*test_coord_down      , label='coord down')\n",
    "axe.set_xlabel(str_coord, weight='bold', fontsize=16)\n",
    "axe.legend()\n",
    "\n",
    "\n",
    "if not(loop):\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#thesis plot\n",
    "\n",
    "plt.close('all')\n",
    "plt.figure()\n",
    "gs = GridSpec(2, 1)\n",
    "\n",
    "axe = plt.subplot(gs[0])\n",
    "axe.plot(coord, b_slice, label='Magnetic field')\n",
    "axe.set_ylabel('B (nT)', weight='bold', fontsize='14')\n",
    "axe.set_xlabel('x (di)', weight='bold', fontsize='14')\n",
    "axe.set_ylim([-1.5,35])\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[1])\n",
    "axe.plot(coord, j_slice, label='Electric current')\n",
    "plt.scatter(coord[maximums], j_slice[maximums], label='local maximas')\n",
    "axe.set_ylabel('J (nA/mÂ²)', weight='bold', fontsize='14')\n",
    "axe.set_xlabel('y (di)', weight='bold', fontsize='14')\n",
    "axe.set_ylim([-1.5,15])\n",
    "# axe.axvline(coord_bow_shock_up   , color='red', label=\"bow shock up\")\n",
    "# axe.axvline(coord_bow_shock_down , color='red', label=\"bow shock down\")\n",
    "# axe.set_xlim([min(coord), abs(min(coord))])\n",
    "axe.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(x[35:50], np.gradient(b_slice)[35:50])\n",
    "# plt.axvline(coord_bow_shock_up   , color='red', label=\"bow shock up\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### magnetopause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# When the magnetopause is misplaced, these next few cells should help understand why\n",
    "dl = 2\n",
    "\n",
    "str_coord='Z'\n",
    "\n",
    "\n",
    "if (str_coord=='X'):\n",
    "    coord = x\n",
    "    slice_x = slice(None)\n",
    "    slice_y = slice(ny0-dl, ny0+dl)\n",
    "    slice_z = slice(nz0-dl, nz0+dl)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    #Values for x are higher, because the shock takes the solar wind head-on\n",
    "    #Dividing b_slice by 2 allows to use the same test for all coords.\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(1, 2))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(1, 2))/2\n",
    "    jx_slice = abs(MD.Jx(B, slices)).mean(axis=(1, 2))\n",
    "    jy_slice = abs(MD.Jy(B, slices)).mean(axis=(1, 2))\n",
    "    jz_slice = abs(MD.Jz(B, slices)).mean(axis=(1, 2))\n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(1, 2))/2\n",
    "    n_slice = N[slices].mean(axis=(1, 2))\n",
    "\n",
    "if (str_coord=='Y'):\n",
    "    coord = y\n",
    "    gstep_coord = abs(np.mean(coord[1:] - coord[:-1]))\n",
    "    slice_x = slice(nx0-dl, nx0+dl)\n",
    "    slice_y = slice(None)\n",
    "    slice_z = slice(nz0-dl, nz0+dl)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(0, 2))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(0, 2))\n",
    "    jx_slice = abs(MD.Jx(B, slices)).mean(axis=(0, 2))\n",
    "    jy_slice = abs(MD.Jy(B, slices)).mean(axis=(0, 2))\n",
    "    jz_slice = abs(MD.Jz(B, slices)).mean(axis=(0, 2))    \n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(0, 2))\n",
    "    n_slice = N[slices].mean(axis=(0, 2))\n",
    "\n",
    "if (str_coord=='Z'):\n",
    "    coord = z\n",
    "    gstep_coord = abs(np.mean(coord[1:] - coord[:-1]))\n",
    "    slice_x = slice(nx0-dl, nx0+dl)\n",
    "    slice_y = slice(ny0-dl, ny0+dl)\n",
    "    slice_z = slice(None)\n",
    "    slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "    b_slice = np.sqrt( Bx[slices]**2\n",
    "                      +By[slices]**2\n",
    "                      +Bz[slices]**2 ).mean(axis=(0, 1))\n",
    "    j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(0, 1))\n",
    "    jx_slice = abs(MD.Jx(B, slices)).mean(axis=(0, 1))\n",
    "    jy_slice = abs(MD.Jy(B, slices)).mean(axis=(0, 1))\n",
    "    jz_slice = abs(MD.Jz(B, slices)).mean(axis=(0, 1))    \n",
    "\n",
    "    v_slice = np.sqrt( Vx[slices]**2\n",
    "                      +Vy[slices]**2\n",
    "                      +Vz[slices]**2 ).mean(axis=(0, 1))\n",
    "    n_slice = N[slices].mean(axis=(0, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_slice = savgol_filter(n_slice, 51, 3)\n",
    "\n",
    "test_planet = (15 < abs(coord)) & (abs(coord) < 80)\n",
    "test_coord_up  = (coord > 0)\n",
    "test_coord_down  = (coord < 0)\n",
    "test_up   = test_coord_up & test_planet\n",
    "test_down = test_coord_down & test_planet\n",
    "test_grad_n_up   = (np.gradient(n_slice) > 0.1*max(np.gradient(n_slice))) & test_coord_up\n",
    "test_grad_n_down = (np.gradient(n_slice) < 0.1*min(np.gradient(n_slice))) & test_coord_down\n",
    "\n",
    "maximums = signal.argrelextrema(j_slice, np.greater, order=4)\n",
    "\n",
    "if str_coord=='X':\n",
    "    #This next line may be convoluted for nothing\n",
    "    #Try: j_max_local_map_up = max(j_slice[test_up])\n",
    "    j_max_local_max_up = max(MD.intersection(j_slice[maximums], j_slice[test_up]))\n",
    "    i_m_up = MD.aplatir(np.where(j_slice == j_max_local_max_up))\n",
    "    coord_magnetopause_up = coord[i_m_up]\n",
    "    coord_magnetopause_down = 0\n",
    "elif (str_coord == 'Y'):\n",
    "    i_m_up = MD.give_center_of_multiple_ones(test_grad_n_up)\n",
    "    coord_magnetopause_up = coord[i_m_up]\n",
    "    i_m_down = MD.give_center_of_multiple_ones(test_grad_n_down)\n",
    "    coord_magnetopause_down = coord[i_m_down]\n",
    "#     j_max_local_max_up = MD.second_largest(j_slice, MD.intersection(j_slice[maximums], j_slice[test_up]))\n",
    "#     i_m_up = MD.aplatir(np.where(j_slice == j_max_local_max_up))\n",
    "#     coord_magnetopause_up = coord[i_m_up]\n",
    "#     j_max_local_max_down = MD.second_largest(j_slice, MD.intersection(j_slice[maximums], j_slice[test_down]))\n",
    "#     i_m_down = MD.aplatir(np.where(j_slice == j_max_local_max_down))\n",
    "#     coord_magnetopause_down = coord[i_m_down]\n",
    "elif (str_coord == 'Z'):\n",
    "    j_max_local_max_up = max(MD.intersection(j_slice[maximums], j_slice[test_up]))\n",
    "    i_m_up = MD.aplatir(np.where(j_slice == j_max_local_max_up))\n",
    "    coord_magnetopause_up = coord[i_m_up]\n",
    "\n",
    "    j_max_local_max_down = max(MD.intersection(j_slice[maximums], j_slice[test_down]))\n",
    "    i_m_down = MD.aplatir(np.where(j_slice == j_max_local_max_down))\n",
    "    coord_magnetopause_down = coord[i_m_down]\n",
    "\n",
    "\n",
    "\n",
    "print(coord_magnetopause_up)\n",
    "print(coord_magnetopause_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# print([(i, test) for (i, test) in enumerate(test_grad_n_down & test_coord_down & test_planet)])\n",
    "# give_center_of_multiple_ones(test_grad_n_down & test_coord_down & test_planet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(15, 5))\n",
    "gs = GridSpec(2, 1)\n",
    "\n",
    "axe = plt.subplot(gs[0])\n",
    "axe.set_xlabel(str_coord, weight='bold', fontsize=16)\n",
    "axe.axvline(coord_magnetopause_up   , color='red', linewidth=3, alpha=0.5, label=\"magnetopause up position\")\n",
    "axe.axvline(coord_magnetopause_down , color='red', linewidth=3, alpha=0.5, label=\"magnetopause down position\")\n",
    "axe.plot(coord, n_slice, label='n slice')\n",
    "axe.plot(coord, np.gradient(n_slice), label = 'grad n slice')\n",
    "if str_coord == 'Y':\n",
    "    axe.plot(coord, 0.1*axe.get_ylim()[1]*test_grad_n_up, label='test_grad_n_up')\n",
    "    axe.plot(coord, 0.1*axe.get_ylim()[1]*test_grad_n_down, label='test_grad_n_down')\n",
    "else:\n",
    "    axe.plot(coord, 0.1*axe.get_ylim()[1]*test_up, label='test_up')\n",
    "    axe.plot(coord, 0.1*axe.get_ylim()[1]*test_down, label='test_down')    \n",
    "axe.set_xlim([min(coord), abs(min(coord))])\n",
    "# axe.set_xlim([-100, 100])\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[1], sharex=axe)\n",
    "axe.set_xlabel(str_coord, weight='bold', fontsize=16)\n",
    "axe.axvline(coord_magnetopause_up   , color='red', linewidth=3, alpha=0.5, label=\"magnetopause up position\")\n",
    "axe.axvline(coord_magnetopause_down , color='red', linewidth=3, alpha=0.5, label=\"magnetopause down position\")\n",
    "axe.plot(coord, j_slice, label='j slice')\n",
    "axe.scatter(coord[maximums], j_slice[maximums], label='local maximas')\n",
    "ymax = 90 #0.1*np.nanmax(j_slice)\n",
    "axe.set_ylim([-1, ymax])\n",
    "# axe.plot(coord, 1000*np.gradient(n_slice), label = '1000*grad n slice')\n",
    "# axe.plot(coord, 0.5*ymax*test_grad_n_up, label='strong up gradient')\n",
    "# axe.plot(coord, 0.5*ymax*test_grad_n_down, label='strong down gradient')\n",
    "axe.legend()\n",
    "\n",
    "\n",
    "if not(loop):\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### IP shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coord = x\n",
    "slice_x = slice(None)\n",
    "slice_y = slice(dl, 3*dl)\n",
    "slice_z = slice(dl, 3*dl)\n",
    "slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "v_slice = np.sqrt( Vx[slices]**2\n",
    "                  +Vy[slices]**2\n",
    "                  +Vz[slices]**2 ).mean(axis=(1, 2))/2\n",
    "n_slice = N[slices].mean(axis=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "grad_n = np.gradient(n_slice)\n",
    "grad_v = np.gradient(v_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ix_ip_shock = np.where(grad_v == np.nanmax(grad_v))\n",
    "x_ip_shock = coord[ix_ip_shock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure()\n",
    "gs = GridSpec(2, 1)\n",
    "\n",
    "axe = plt.subplot(gs[0])\n",
    "axe.plot(coord, v_slice, label='Velocity')\n",
    "axe.set_ylabel('V (km/s)', fontsize='14')\n",
    "axe.axvline(coord[ix_ip_shock], color='red', label=\"ip_shock\")\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend()\n",
    "\n",
    "axe = plt.subplot(gs[1], sharex=axe)\n",
    "axe.plot(coord, grad_v, label='Velocity gradient')\n",
    "axe.set_ylabel(r'$\\nabla_x$ V', fontsize='14')\n",
    "axe.set_xlabel('x (di)', weight='bold', fontsize='14')\n",
    "axe.axvline(coord[ix_ip_shock], color='red', label=\"ip_shock\")\n",
    "axe.legend()\n",
    "\n",
    "\n",
    "if not(loop):\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### MC leading edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "coord = x\n",
    "slice_x = slice(None)\n",
    "slice_y = slice(dl, 3*dl)\n",
    "slice_z = slice(dl, 3*dl)\n",
    "slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "b_slice = np.sqrt( Bx[slices]**2\n",
    "                  +By[slices]**2\n",
    "                  +Bz[slices]**2 ).mean(axis=(1, 2))/2\n",
    "b_slice = savgol_filter(b_slice, 51, 3)\n",
    "j_slice = np.sqrt(sum([ji**2 for ji in MD.J(B, slices)])).mean(axis=(1, 2))\n",
    "v_slice = np.sqrt( Vx[slices]**2\n",
    "                  +Vy[slices]**2\n",
    "                  +Vz[slices]**2 ).mean(axis=(1, 2))/2\n",
    "#For some reason, savgol doesn't always converge,\n",
    "#this way of smoothing is a nice workaround\n",
    "def smooth(y, box_pts):\n",
    "    box = np.ones(box_pts)/box_pts\n",
    "    y_smooth = np.convolve(y, box, mode='same')\n",
    "    return y_smooth\n",
    "v_slice = smooth(v_slice, 51)\n",
    "n_slice = N[slices].mean(axis=(1, 2))\n",
    "n_slice = savgol_filter(n_slice, 51, 3)\n",
    "\n",
    "grad_n = np.gradient(n_slice)\n",
    "# grad_v = np.gradient(v_slice)\n",
    "grad_b = np.gradient(b_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_grad_n = grad_n < -1*np.nanmean(abs(grad_n))\n",
    "test_grad_b = grad_b > 1*np.nanmean(abs(grad_b))\n",
    "test_non_absurd = (abs(coord) < 800) & (abs(coord - x_ip_shock) > 45)\n",
    "test_le = test_grad_n & test_grad_b & test_non_absurd #& test_grad_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    ix_mc_leading_edge = np.where(j_slice == np.nanmax(j_slice[np.where(test_le)]))\n",
    "    x_mc_leading_edge = x[ix_mc_leading_edge]\n",
    "except ValueError:\n",
    "    x_mc_leading_edge = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.close('all')\n",
    "plt.figure(figsize=(8, 10))\n",
    "gs = GridSpec(8, 1)\n",
    "\n",
    "axe = plt.subplot(gs[0])\n",
    "axe.plot(coord, n_slice, label='Density')\n",
    "axe.set_ylabel(r'N (nb.cm$^{-3}$)', fontsize='14')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.invert_xaxis()\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[1], sharex=axe)\n",
    "axe.plot(coord, b_slice, label='Magnetic field')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.set_ylim([-1.5,65])\n",
    "axe.set_ylabel('B (nT)', fontsize='14')\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[2], sharex=axe)\n",
    "axe.plot(coord, v_slice, label='Velocity')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.set_ylabel('V (km/s)', fontsize='14')\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[3], sharex=axe)\n",
    "axe.plot(coord, j_slice, label='Current')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.set_ylim([-1.5,18])\n",
    "axe.set_ylabel('J (nA/mÂ²)', fontsize='14')\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[4], sharex=axe)\n",
    "axe.plot(coord, grad_n, label='grad_n')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.set_ylim([-5,5])\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[5], sharex=axe)\n",
    "axe.plot(coord, test_grad_n, label='test_grad_n')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[6], sharex=axe)\n",
    "axe.plot(coord, grad_b, label='grad_b')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.set_ylim([-5,5])\n",
    "axe.get_xaxis().set_visible(False)\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "axe = plt.subplot(gs[7], sharex=axe)\n",
    "axe.plot(coord, test_grad_b, label='test_grad_b')\n",
    "axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "axe.legend(loc='center left')\n",
    "\n",
    "# axe = plt.subplot(gs[8], sharex=axe)\n",
    "# axe.plot(coord, grad_v)\n",
    "# axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "# axe.set_ylim([-5,5])\n",
    "# axe.set_ylabel(r'$\\nabla_x$ B (nT)', fontsize='14')\n",
    "# axe.get_xaxis().set_visible(False)\n",
    "# axe.legend(loc='center left')\n",
    "\n",
    "# axe = plt.subplot(gs[9], sharex=axe)\n",
    "# axe.plot(coord, test_grad_v, label='test_grad_v')\n",
    "# axe.axvline(x_mc_leading_edge, color='red', label=\"leading_edge\")\n",
    "# axe.legend(loc='center left')\n",
    "\n",
    "\n",
    "if not(loop):\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute global geometry & shock normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Locate bow shock and magnetopause    \n",
    "\n",
    "x_bow_shock, x_magnetopause, y_bow_shock_up, y_bow_shock_down, y_magnetopause_up, y_magnetopause_down, z_bow_shock_up, z_bow_shock_down, z_magnetopause_up, z_magnetopause_down = MD.compute_global_geometry(B, N, V, metadata, time)\n",
    "\n",
    "boxes = MD.create_boxes_dictionary()\n",
    "\n",
    "x_ip_shock = MD.find_ip_shock(V, metadata, time)\n",
    "x_mc_leading_edge = MD.find_mc_leading_edge(B, N, metadata, time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "chances = [1, 2, 3, 4]\n",
    "\n",
    "while len(chances)>0:\n",
    "    chances.pop()\n",
    "    print(f\"{len(chances)} chances left to compute boundaries\")\n",
    "\n",
    "    global_geometry = { 'x_bow_shock': x_bow_shock, 'x_magnetopause': x_magnetopause,\n",
    "                        'y_bow_shock_up': y_bow_shock_up, 'y_bow_shock_down': y_bow_shock_down,\n",
    "                        'y_magnetopause_up': y_magnetopause_up, 'y_magnetopause_down': y_magnetopause_down,\n",
    "                        'z_bow_shock_up': z_bow_shock_up, 'z_bow_shock_down': z_bow_shock_down, \n",
    "                        'z_magnetopause_up': z_magnetopause_up, 'z_magnetopause_down': z_magnetopause_down,\n",
    "                        'x_ip_shock': x_ip_shock, 'x_mc_leading_edge': x_mc_leading_edge }\n",
    "\n",
    "    number_of_absurdities = 0\n",
    "    for entry in global_geometry:\n",
    "        absurdity = MD.check_for_absurdities(path_json, entry, time, global_geometry[entry])\n",
    "        if not(absurdity):\n",
    "            print(\"\"\"Absurdities are not defined. This is either because no json_file exists yet, or because\n",
    "                     this is the first time dump\"\"\")\n",
    "            break\n",
    "        if absurdity['absurd']:\n",
    "            number_of_absurdities = number_of_absurdities + 1\n",
    "\n",
    "            if absurdity['entry'] == 'x_bow_shock':\n",
    "                x_bow_shock, _, _, _, _, _, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {x_bow_shock}\")\n",
    "            if absurdity['entry'] == 'x_magnetopause':\n",
    "                _, x_magnetopause, _, _, _, _, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {x_magnetopause}\")\n",
    "            if absurdity['entry'] == 'y_bow_shock_up':\n",
    "                _, _, y_bow_shock_up, _, _, _, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {y_bow_shock_up}\")\n",
    "            if absurdity['entry'] == 'y_bow_shock_down':\n",
    "                _, _, _,  y_bow_shock_down, _, _, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {y_bow_shock_down}\")\n",
    "            if absurdity['entry'] == 'y_magnetopause_up':\n",
    "                _, _, _, _, y_magnetopause_up, _, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {y_magnetopause_up}\")\n",
    "            if absurdity['entry'] == 'y_magnetopause_down':\n",
    "                _, _, _, _, _, y_magnetopause_down, _, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {y_magnetopause_down}\")\n",
    "            if absurdity['entry'] == 'z_bow_shock_up':\n",
    "                _, _, _, _, _, _, z_bow_shock_up, _, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {z_bow_shock_up}\")\n",
    "            if absurdity['entry'] == 'z_bow_shock_down':\n",
    "                _, _, _, _, _, _, _, z_bow_shock_down, _, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {z_bow_shock_down}\")            \n",
    "            if absurdity['entry'] == 'z_magnetopause_up':\n",
    "                _, _, _, _, _, _, _, _, z_magnetopause_up, _ = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {z_magnetopause_up}\")\n",
    "            if absurdity['entry'] == 'z_magnetopause_down':\n",
    "                _, _, _, _, _, _, _, _, _, z_magnetopause_down = MD.compute_global_geometry(B, N, V, metadata, time, absurdity)\n",
    "                print(f\"New value for {absurdity['entry']} is {z_magnetopause_down}\")\n",
    "                    \n",
    "            if absurdity['entry'] == 'x_ip_shock':\n",
    "                x_ip_shock = MD.x_is.item()\n",
    "                print(\"Be careful, changes of x_ip_shock have not been implemented, nothing changed\")\n",
    "            if absurdity['entry'] ==  'x_mc_leading_edge':\n",
    "                x_mc_leading_edge = MD.find_mc_leading_edge(B, N, metadata, time, absurdity=absurdity).item()\n",
    "                print(f\"New value for {absurdity['entry']} is {x_mc_leading_edge}\")\n",
    "        \n",
    "    print(f\"there were {number_of_absurdities} absurdities in the computation of the global geometry\")\n",
    "    if number_of_absurdities==0:\n",
    "        print(\"everything seems alright, let's roll on\")\n",
    "        break\n",
    "if len(chances)==0:\n",
    "    print(f\"time dump {time_label} seems to have some issues. Check the positions of the boundaries!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #This is ill-defined. The local \"upstream\" of each box should be defined by following velocity stream lines\n",
    "\n",
    "# normales = {}\n",
    "\n",
    "# for box in boxes:\n",
    "#     loc = boxes[box]['center']\n",
    "#     origin, vector = MD.bow_shock_normale(loc, B, N, V)\n",
    "#     print(f\"normale for {box} box is {vector} at origin {origin}\")\n",
    "#     normales.update({  f'{box}': {'origin': origin,\n",
    "#                                   'vector': vector}  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for box in boxes:\n",
    "#     loc = boxes[box]['center']\n",
    "#     dict_params = MD.calculate_bow_shock_parameters(loc, B, N, V, T)\n",
    "#     print(MD.color.BOLD + f\"shock params for {box}:\" + MD.color.END)        \n",
    "#     for param in dict_params:\n",
    "#           print(f'{param}: {dict_params[param]:0.2g}')\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normales_xy = {}\n",
    "\n",
    "# for box in ['nose', 'yup', 'ydown']:\n",
    "#     loc = boxes[box]['center']\n",
    "#     origin, vector = MD.bow_shock_normale(loc, B, N, V)\n",
    "#     print(f\"normale for {box} box is {vector} at origin {origin}\")\n",
    "#     normales_xy.update({  f'{box}': {'origin': origin,\n",
    "#                                      'vector': vector}  })\n",
    "    \n",
    "# normales_xz = {}\n",
    "\n",
    "# for box in ['nose', 'zup', 'zdown']:\n",
    "#     loc = boxes[box]['center']\n",
    "#     origin, vector = MD.bow_shock_normale(loc, B, N, V)\n",
    "#     print(f\"normale for {box} box is {vector} at origin {origin}\")\n",
    "#     normales_xz.update({  f'{box}': {'origin': origin,\n",
    "#                                      'vector': vector}  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Actual plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xmin = min(x)\n",
    "xmax = 3*abs(xmin)   #Most of the length in the x direction is used to give space for the sheath to form\n",
    "                     #It is not really interesting\n",
    "zoom = (xmin, xmax, min(y), max(y), min(z), max(z))\n",
    "\n",
    "# lw = 2*np.sqrt(Bx.transpose()**2 + Bj.transpose()**2) / np.mean(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Magnetic field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mag_B = np.sqrt( Bx[:,:,nz0]**2\n",
    "                +By[:,:,nz0]**2\n",
    "                +Bz[:,:,nz0]**2 )\n",
    "\n",
    "magplot = MD.plot_colormap(mag_B, title = f'B in plane (x,y) at {time}', label = 'B (nT)', plane = 'xy',\n",
    "                 ratio_max_to_med = 1.4, with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom, density = 1.5, \n",
    "                 streamplot = True, Bx = Bx[:,:,nz0], Bj = By[:,:,nz0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mag_B = np.sqrt( Bx[:,ny0,:]**2\n",
    "                +By[:,ny0,:]**2\n",
    "                +Bz[:,ny0,:]**2 )\n",
    "\n",
    "MD.plot_colormap(mag_B, f'B in plane (x,z) at {time}', 'B (nT)', 'xz',\n",
    "                 ratio_max_to_med = 1.4, with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom, density = 1.5,\n",
    "                 streamplot = True, Bx = Bx[:,ny0,:], Bj = Bz[:,ny0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Plasma density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MD.plot_colormap(N[:,:,nz0], f'N in plane (x,y) at {time}', r'N (cm$^{-3}$)', 'xy',\n",
    "                 with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "MD.plot_colormap(N[:,ny0,:], f'N in plane (x,z) at {time}', r'N (cm$^{-3}$)', 'xz',\n",
    "                 with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "slice_x = slice(None)\n",
    "slice_y = slice(None)\n",
    "slice_z = slice(nz0-1, nz0+1)\n",
    "slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "mag_J = np.sqrt(MD.Jx(B, slices)[:,:,1]**2 + MD.Jy(B, slices)[:,:,1]**2 + MD.Jz(B, slices)[:,:,1]**2)\n",
    "\n",
    "MD.plot_colormap(mag_J, f'J in plane (x,y) at {time}', 'J (nA/mÂ²)', 'xy', ratio_max_to_med = 80,\n",
    "                 with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "slice_x = slice(None)\n",
    "slice_y = slice(ny0-1, ny0+1)\n",
    "slice_z = slice(None)\n",
    "slices = (slice_x, slice_y, slice_z)\n",
    "\n",
    "mag_J = np.sqrt(MD.Jx(B, slices)[:,1,:]**2 + MD.Jy(B, slices)[:,1,:]**2 + MD.Jz(B, slices)[:,1,:]**2)\n",
    "\n",
    "MD.plot_colormap(mag_J, f'J in plane (x,z) at {time}', 'J (nA/mÂ²)', 'xz', ratio_max_to_med = 80,\n",
    "                 with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Velocity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Note: ideally, the last flow line should be a good definition of the magnetopause. Unfortunately, many 'nan' in the velocity make it impractical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mag_V = np.sqrt( Vx[:,:,nz0]**2\n",
    "                +Vy[:,:,nz0]**2\n",
    "                +Vz[:,:,nz0]**2 )\n",
    "\n",
    "np.nan_to_num(mag_V, 0)\n",
    "\n",
    "magplot = MD.plot_colormap(mag_V, title = f'V in plane (x,y) at {time}', label = 'V (km/s)', plane = 'xy',\n",
    "                 ratio_max_to_med = 1.4, with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom, density = 5.5, \n",
    "                 streamplot = True, Bx = Vx[:,:,nz0], Bj = Vy[:,:,nz0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mag_V = np.sqrt( Vx[:,ny0,:]**2\n",
    "                +Vy[:,ny0,:]**2\n",
    "                +Vz[:,ny0,:]**2 )\n",
    "\n",
    "np.nan_to_num(mag_V, 0)\n",
    "\n",
    "magplot = MD.plot_colormap(mag_V, title = f'V in plane (x,z) at {time}', label = 'V (km/s)', plane = 'xz',\n",
    "                 ratio_max_to_med = 1.4, with_dots = True, normales = None, loop = loop,\n",
    "                 save_dir = storing_directory, t_label = time_label,\n",
    "                 zoom = zoom, density = 5.5, \n",
    "                 streamplot = True, Bx = Vx[:,ny0,:], Bj = Vz[:,ny0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "\n",
    "if not(loop):\n",
    "    MD.plot_boxes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ixmax = MD.aplatir(np.where(x>=xmax))[0]\n",
    "N_and_boxes = N[:ixmax, :, :].copy() #No need to plot the whole x_direction, it is mostly solar wind\n",
    "\n",
    "boxes = MD.create_boxes_dictionary()\n",
    "\n",
    "for box in boxes:   \n",
    "    ixmax,ixmin,iymax,iymin,izmax,izmin = MD.construct_box_indexes(box,\n",
    "                                                                   boxes[box][\"coord_bow_shock\"],\n",
    "                                                                   boxes[box]['coord_magnetopause'])\n",
    "\n",
    "    slices = (slice(ixmin, ixmax), slice(iymin, iymax), slice(izmin, izmax))    \n",
    "\n",
    "    N_and_boxes[slices] = 0 #Put the density to zero in the boxes, so that they are easy to spot on a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# for box in boxes:   \n",
    "    \n",
    "#     origin = normales[box]['origin']\n",
    "#     magnetosheath_half_width = abs(x_bow_shock-x_magnetopause)/2\n",
    "\n",
    "#     loc_upstream = (origin[0]+2*magnetosheath_half_width, origin[1], origin[2])\n",
    "#     xmin, ymin, zmin = loc_upstream[0]-MD.size_cubes/2, loc_upstream[1]-MD.size_cubes/2, loc_upstream[2]-MD.size_cubes/2\n",
    "#     xmax, ymax, zmax = loc_upstream[0]+MD.size_cubes/2, loc_upstream[1]+MD.size_cubes/2, loc_upstream[2]+MD.size_cubes/2\n",
    "#     ixmin, iymin, izmin = MD.convert_coord_to_indices((xmin, ymin, zmin))\n",
    "#     ixmax, iymax, izmax = MD.convert_coord_to_indices((xmax, ymax, zmax))\n",
    "\n",
    "#     slice_upstream = (slice(ixmin, ixmax), slice(iymin, iymax), slice(izmin, izmax)) \n",
    "\n",
    "#     N_and_boxes[slice_upstream] = np.max(N) #Put the density to max(N) in the boxes, so that they are easy to spot on a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not(loop):\n",
    "    \n",
    "    %matplotlib notebook\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    tracker = IndexTracker(ax, N_and_boxes, 'xy')\n",
    "\n",
    "    fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate relevant data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Size of the magnetosheath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "size_nose  = abs(  x_bow_shock      - x_magnetopause       )\n",
    "size_yup   = abs(  y_bow_shock_up   - y_magnetopause_up    )\n",
    "size_ydown = abs(  y_bow_shock_down - y_magnetopause_down  )\n",
    "size_zup   = abs(  z_bow_shock_up   - z_magnetopause_up    )\n",
    "size_zdown = abs(  z_bow_shock_down - z_magnetopause_down  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data in cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "B_upstream, B_nose, B_yup, B_ydown, B_zup, B_zdown = MD.compute_data_in_cubes(B)\n",
    "print(B_upstream, B_nose,B_yup,B_ydown,B_zup,B_zdown)\n",
    "\n",
    "Bx_upstream, Bx_nose, Bx_yup, Bx_ydown, Bx_zup, Bx_zdown = MD.compute_data_in_cubes(Bx)\n",
    "By_upstream, By_nose, By_yup, By_ydown, By_zup, By_zdown = MD.compute_data_in_cubes(By)\n",
    "Bz_upstream, Bz_nose, Bz_yup, Bz_ydown, Bz_zup, Bz_zdown = MD.compute_data_in_cubes(Bz)\n",
    "\n",
    "E_upstream, E_nose, E_yup, E_ydown, E_zup, E_zdown = MD.compute_data_in_cubes(E)\n",
    "print(E_upstream, E_nose,E_yup,E_ydown,E_zup,E_zdown)\n",
    "\n",
    "Ex_upstream, Ex_nose, Ex_yup, Ex_ydown, Ex_zup, Ex_zdown = MD.compute_data_in_cubes(Ex)\n",
    "Ey_upstream, Ey_nose, Ey_yup, Ey_ydown, Ey_zup, Ey_zdown = MD.compute_data_in_cubes(Ey)\n",
    "Ez_upstream, Ez_nose, Ez_yup, Ez_ydown, Ez_zup, Ez_zdown = MD.compute_data_in_cubes(Ez)\n",
    "\n",
    "N_upstream, N_nose, N_yup, N_ydown, N_zup, N_zdown = MD.compute_data_in_cubes(N)\n",
    "print(N_upstream, N_nose,N_yup,N_ydown,N_zup,N_zdown)\n",
    "\n",
    "T_upstream, T_nose, T_yup, T_ydown, T_zup, T_zdown = MD.compute_data_in_cubes(T)\n",
    "print(T_upstream, T_nose,T_yup,T_ydown,T_zup,T_zdown)\n",
    "\n",
    "V_upstream, V_nose, V_yup, V_ydown, V_zup, V_zdown = MD.compute_data_in_cubes(V)\n",
    "print(V_upstream, V_nose,V_yup,V_ydown,V_zup,V_zdown)\n",
    "\n",
    "Vx_upstream, Vx_nose, Vx_yup, Vx_ydown, Vx_zup, Vx_zdown = MD.compute_data_in_cubes(Vx)\n",
    "Vy_upstream, Vy_nose, Vy_yup, Vy_ydown, Vy_zup, Vy_zdown = MD.compute_data_in_cubes(Vy)\n",
    "Vz_upstream, Vz_nose, Vz_yup, Vz_ydown, Vz_zup, Vz_zdown = MD.compute_data_in_cubes(Vz)\n",
    "\n",
    "print(\"calculating J\")\n",
    "J_upstream, J_nose, J_yup, J_ydown, J_zup, J_zdown = MD.compute_data_in_cubes(B, function1=MD.J)\n",
    "print(J_upstream, J_nose, J_yup, J_ydown, J_zup, J_zdown)\n",
    "\n",
    "Jx_upstream, Jx_nose, Jx_yup, Jx_ydown, Jx_zup, Jx_zdown = MD.compute_data_in_cubes(B, function1=MD.Jx)\n",
    "Jy_upstream, Jy_nose, Jy_yup, Jy_ydown, Jy_zup, Jy_zdown = MD.compute_data_in_cubes(B, function1=MD.Jy)\n",
    "Jz_upstream, Jz_nose, Jz_yup, Jz_ydown, Jz_zup, Jz_zdown = MD.compute_data_in_cubes(B, function1=MD.Jz)\n",
    "\n",
    "JE_upstream, JE_nose, JE_yup, JE_ydown, JE_zup, JE_zdown = MD.compute_data_in_cubes(data1=B, data2=E,\n",
    "                                                                                    function1=MD.J,\n",
    "                                                                                    function_both=MD.dot_product)\n",
    "print(JE_upstream, JE_nose,JE_yup,JE_ydown,JE_zup,JE_zdown)\n",
    "\n",
    "JxB_upstream, JxB_nose, JxB_yup, JxB_ydown, JxB_zup, JxB_zdown = MD.compute_data_in_cubes(data1=B, data2=B,\n",
    "                                                                                          function1=MD.J,\n",
    "                                                                                          function_both=MD.cross_product)\n",
    "print(JxB_upstream, JxB_nose, JxB_yup, JxB_ydown, JxB_zup, JxB_zdown)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#conversion to SI:\n",
    "b = 1e-9\n",
    "n = 1e6\n",
    "v = 1e3\n",
    "t = 11605\n",
    "#put pressure in nPa\n",
    "p = 1e9\n",
    "\n",
    "Pmag_upstream, Pmag_nose, Pmag_yup, Pmag_ydown, Pmag_zup, Pmag_zdown = MD.compute_data_in_cubes(p*(b*MD.norm(B))**2/(2*MD.Âµ0))\n",
    "print(Pmag_upstream, Pmag_nose,Pmag_yup,Pmag_ydown,Pmag_zup,Pmag_zdown)\n",
    "\n",
    "Pdyn_upstream, Pdyn_nose, Pdyn_yup, Pdyn_ydown, Pdyn_zup, Pdyn_zdown = MD.compute_data_in_cubes(p*(1./2)*MD.mp*(n*N)*(v*MD.norm(V))**2)\n",
    "print(Pdyn_upstream, Pdyn_nose,Pdyn_yup,Pdyn_ydown,Pdyn_zup,Pdyn_zdown)\n",
    "\n",
    "Pth_upstream, Pth_nose, Pth_yup, Pth_ydown, Pth_zup, Pth_zdown = MD.compute_data_in_cubes(p*MD.kB*(n*N)*(t*T))\n",
    "print(Pth_upstream, Pth_nose,Pth_yup,Pth_ydown,Pth_zup,Pth_zdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Beta_upstream, Beta_nose, Beta_yup, Beta_ydown, Beta_zup, Beta_zdown = MD.compute_data_in_cubes(MD.kB*(n*N)*(t*T)*(2*MD.Âµ0/(b*MD.norm(B))**2))\n",
    "print(Beta_upstream, Beta_nose,Beta_yup,Beta_ydown,Beta_zup,Beta_zdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### RMS in cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"rmsB's\")\n",
    "\n",
    "rmsBx_upstream, rmsBx_nose, rmsBx_yup, rmsBx_ydown, rmsBx_zup, rmsBx_zdown, test_rms_Bx = MD.compute_RMS_in_cubes(Bx)\n",
    "print(rmsBx_upstream, rmsBx_nose,rmsBx_yup,rmsBx_ydown,rmsBx_zup,rmsBx_zdown)\n",
    "\n",
    "rmsBy_upstream, rmsBy_nose, rmsBy_yup, rmsBy_ydown, rmsBy_zup, rmsBy_zdown, test_rms_By = MD.compute_RMS_in_cubes(By)\n",
    "print(rmsBy_upstream, rmsBy_nose,rmsBy_yup,rmsBy_ydown,rmsBy_zup,rmsBy_zdown)\n",
    "\n",
    "rmsBz_upstream, rmsBz_nose, rmsBz_yup, rmsBz_ydown, rmsBz_zup, rmsBz_zdown, test_rms_Bz = MD.compute_RMS_in_cubes(Bz)\n",
    "print(rmsBz_upstream, rmsBz_nose,rmsBz_yup,rmsBz_ydown,rmsBz_zup,rmsBz_zdown)\n",
    "\n",
    "rmsB_upstream = np.sqrt( rmsBx_upstream**2 + rmsBy_upstream**2 + rmsBz_upstream**2 )\n",
    "rmsB_nose = np.sqrt( rmsBx_nose**2 + rmsBy_nose**2 + rmsBz_nose**2 )\n",
    "rmsB_yup = np.sqrt( rmsBx_yup**2 + rmsBy_yup**2 + rmsBz_yup**2 )\n",
    "rmsB_ydown = np.sqrt( rmsBx_ydown**2 + rmsBy_ydown**2 + rmsBz_ydown**2 )\n",
    "rmsB_zup = np.sqrt( rmsBx_zup**2 + rmsBy_zup**2 + rmsBz_zup**2 )\n",
    "rmsB_zdown = np.sqrt( rmsBx_zdown**2 + rmsBy_zdown**2 + rmsBz_zdown**2 )\n",
    "\n",
    "print(rmsB_upstream, rmsB_nose,rmsB_yup,rmsB_ydown,rmsB_zup,rmsB_zdown)\n",
    "\n",
    "print(\"rmsBoB's\")\n",
    "\n",
    "rmsBoB_upstream = rmsB_upstream / B_upstream\n",
    "rmsBoB_nose = rmsB_nose / B_nose\n",
    "rmsBoB_yup = rmsB_yup / B_yup\n",
    "rmsBoB_ydown = rmsB_ydown / B_ydown\n",
    "rmsBoB_zup = rmsB_zup / B_zup\n",
    "rmsBoB_zdown = rmsB_zdown / B_zdown\n",
    "\n",
    "print(rmsBoB_upstream, rmsBoB_nose,rmsBoB_yup,rmsBoB_ydown,rmsBoB_zup,rmsBoB_zdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### test rms plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not(loop):\n",
    "    \n",
    "    %matplotlib notebook\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "    tracker = IndexTracker(ax, test_rms_Bz['upstream'], 'yz')\n",
    "\n",
    "    fig.canvas.mpl_connect('scroll_event', tracker.onscroll)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store relevant data for the current time dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = MD.create_boxes_dictionary()\n",
    "boxes = MD.make_boxes_JSON_serializable(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ip_shock.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mc_leading_edge.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#     .json files are not happy with numbers with a type = np.float32\n",
    "#     a.item() converts a from np.float32 to float\n",
    "\n",
    "relevant_data = { \"x_ip_shock\"        : x_ip_shock.item()        , \n",
    "                  \"x_mc_leading_edge\" : x_mc_leading_edge.item() ,\n",
    "                  \"size_nose\"  : size_nose.item()  ,\n",
    "                  \"size_yup\"   : size_yup.item()   ,\n",
    "                  \"size_ydown\" : size_ydown.item() ,\n",
    "                  \"size_zup\"   : size_zup.item()   , \n",
    "                  \"size_zdown\" : size_zdown.item() , \n",
    "                  \"x_bow_shock\"        : x_bow_shock.item(),\n",
    "                  \"x_magnetopause\"     : x_magnetopause.item(),\n",
    "                  \"y_bow_shock_up\"     : y_bow_shock_up.item(),\n",
    "                  \"y_bow_shock_down\"   : y_bow_shock_down.item(),\n",
    "                  \"y_magnetopause_up\"  : y_magnetopause_up.item(),\n",
    "                  \"y_magnetopause_down\": y_magnetopause_down.item(),\n",
    "                  \"z_bow_shock_up\"     : z_bow_shock_up.item(),\n",
    "                  \"z_bow_shock_down\"   : z_bow_shock_down.item(),\n",
    "                  \"z_magnetopause_up\"  : z_magnetopause_up.item(),\n",
    "                  \"z_magnetopause_down\": z_magnetopause_down.item(),    \n",
    "                  \"boxes\": boxes,\n",
    "                  \"B_upstream\"  : B_upstream.item()  ,\n",
    "                  \"B_nose\"  : B_nose.item()  ,\n",
    "                  \"B_yup\"   : B_yup.item()   ,\n",
    "                  \"B_ydown\" : B_ydown.item() ,\n",
    "                  \"B_zup\"   : B_zup.item()   , \n",
    "                  \"B_zdown\" : B_zdown.item() , \n",
    "                  \"Bx_upstream\"  : Bx_upstream.item()  ,\n",
    "                  \"Bx_nose\"  : Bx_nose.item()  ,\n",
    "                  \"Bx_yup\"   : Bx_yup.item()   ,\n",
    "                  \"Bx_ydown\" : Bx_ydown.item() ,\n",
    "                  \"Bx_zup\"   : Bx_zup.item()   , \n",
    "                  \"Bx_zdown\" : Bx_zdown.item() , \n",
    "                  \"By_upstream\"  : By_upstream.item()  ,\n",
    "                  \"By_nose\"  : By_nose.item()  ,\n",
    "                  \"By_yup\"   : By_yup.item()   ,\n",
    "                  \"By_ydown\" : By_ydown.item() ,\n",
    "                  \"By_zup\"   : By_zup.item()   , \n",
    "                  \"By_zdown\" : By_zdown.item() , \n",
    "                  \"Bz_upstream\"  : Bz_upstream.item()  ,\n",
    "                  \"Bz_nose\"  : Bz_nose.item()  ,\n",
    "                  \"Bz_yup\"   : Bz_yup.item()   ,\n",
    "                  \"Bz_ydown\" : Bz_ydown.item() ,\n",
    "                  \"Bz_zup\"   : Bz_zup.item()   , \n",
    "                  \"Bz_zdown\" : Bz_zdown.item() , \n",
    "                  \"E_upstream\"  : E_upstream.item()  ,\n",
    "                  \"E_nose\"  : E_nose.item()  ,\n",
    "                  \"E_yup\"   : E_yup.item()   ,\n",
    "                  \"E_ydown\" : E_ydown.item() ,\n",
    "                  \"E_zup\"   : E_zup.item()   , \n",
    "                  \"E_zdown\" : E_zdown.item() , \n",
    "                  \"Ex_upstream\"  : Ex_upstream.item()  ,\n",
    "                  \"Ex_nose\"  : Ex_nose.item()  ,\n",
    "                  \"Ex_yup\"   : Ex_yup.item()   ,\n",
    "                  \"Ex_ydown\" : Ex_ydown.item() ,\n",
    "                  \"Ex_zup\"   : Ex_zup.item()   , \n",
    "                  \"Ex_zdown\" : Ex_zdown.item() , \n",
    "                  \"Ey_upstream\"  : Ey_upstream.item()  ,\n",
    "                  \"Ey_nose\"  : Ey_nose.item()  ,\n",
    "                  \"Ey_yup\"   : Ey_yup.item()   ,\n",
    "                  \"Ey_ydown\" : Ey_ydown.item() ,\n",
    "                  \"Ey_zup\"   : Ey_zup.item()   , \n",
    "                  \"Ey_zdown\" : Ey_zdown.item() , \n",
    "                  \"Ez_upstream\"  : Ez_upstream.item()  ,\n",
    "                  \"Ez_nose\"  : Ez_nose.item()  ,\n",
    "                  \"Ez_yup\"   : Ez_yup.item()   ,\n",
    "                  \"Ez_ydown\" : Ez_ydown.item() ,\n",
    "                  \"Ez_zup\"   : Ez_zup.item()   , \n",
    "                  \"Ez_zdown\" : Ez_zdown.item() , \n",
    "                  \"N_upstream\"  : N_upstream.item()  ,\n",
    "                  \"N_nose\"  : N_nose.item()  ,\n",
    "                  \"N_yup\"   : N_yup.item()   ,\n",
    "                  \"N_ydown\" : N_ydown.item() ,\n",
    "                  \"N_zup\"   : N_zup.item()   , \n",
    "                  \"N_zdown\" : N_zdown.item() ,\n",
    "                  \"T_upstream\"  : T_upstream.item()  ,\n",
    "                  \"T_nose\"  : T_nose.item()  ,\n",
    "                  \"T_yup\"   : T_yup.item()   ,\n",
    "                  \"T_ydown\" : T_ydown.item() ,\n",
    "                  \"T_zup\"   : T_zup.item()   , \n",
    "                  \"T_zdown\" : T_zdown.item() ,\n",
    "                  \"V_upstream\"  : V_upstream.item()  ,\n",
    "                  \"V_nose\"  : V_nose.item()  ,\n",
    "                  \"V_yup\"   : V_yup.item()   ,\n",
    "                  \"V_ydown\" : V_ydown.item() ,\n",
    "                  \"V_zup\"   : V_zup.item()   , \n",
    "                  \"V_zdown\" : V_zdown.item() , \n",
    "                  \"Vx_upstream\"  : Vx_upstream.item()  ,\n",
    "                  \"Vx_nose\"  : Vx_nose.item()  ,\n",
    "                  \"Vx_yup\"   : Vx_yup.item()   ,\n",
    "                  \"Vx_ydown\" : Vx_ydown.item() ,\n",
    "                  \"Vx_zup\"   : Vx_zup.item()   , \n",
    "                  \"Vx_zdown\" : Vx_zdown.item() , \n",
    "                  \"Vy_upstream\"  : Vy_upstream.item()  ,\n",
    "                  \"Vy_nose\"  : Vy_nose.item()  ,\n",
    "                  \"Vy_yup\"   : Vy_yup.item()   ,\n",
    "                  \"Vy_ydown\" : Vy_ydown.item() ,\n",
    "                  \"Vy_zup\"   : Vy_zup.item()   , \n",
    "                  \"Vy_zdown\" : Vy_zdown.item() , \n",
    "                  \"Vz_upstream\"  : Vz_upstream.item()  ,\n",
    "                  \"Vz_nose\"  : Vz_nose.item()  ,\n",
    "                  \"Vz_yup\"   : Vz_yup.item()   ,\n",
    "                  \"Vz_ydown\" : Vz_ydown.item() ,\n",
    "                  \"Vz_zup\"   : Vz_zup.item()   , \n",
    "                  \"Vz_zdown\" : Vz_zdown.item() , \n",
    "                  \"J_upstream\"  : J_upstream.item()  ,\n",
    "                  \"J_nose\"  : J_nose.item()  ,\n",
    "                  \"J_yup\"   : J_yup.item()   ,\n",
    "                  \"J_ydown\" : J_ydown.item() ,\n",
    "                  \"J_zup\"   : J_zup.item()   , \n",
    "                  \"J_zdown\" : J_zdown.item() , \n",
    "                  \"Jx_upstream\"  : Jx_upstream.item()  ,\n",
    "                  \"Jx_nose\"  : Jx_nose.item()  ,\n",
    "                  \"Jx_yup\"   : Jx_yup.item()   ,\n",
    "                  \"Jx_ydown\" : Jx_ydown.item() ,\n",
    "                  \"Jx_zup\"   : Jx_zup.item()   , \n",
    "                  \"Jx_zdown\" : Jx_zdown.item() , \n",
    "                  \"Jy_upstream\"  : Jy_upstream.item()  ,\n",
    "                  \"Jy_nose\"  : Jy_nose.item()  ,\n",
    "                  \"Jy_yup\"   : Jy_yup.item()   ,\n",
    "                  \"Jy_ydown\" : Jy_ydown.item() ,\n",
    "                  \"Jy_zup\"   : Jy_zup.item()   , \n",
    "                  \"Jy_zdown\" : Jy_zdown.item() , \n",
    "                  \"Jz_upstream\"  : Jz_upstream.item()  ,\n",
    "                  \"Jz_nose\"  : Jz_nose.item()  ,\n",
    "                  \"Jz_yup\"   : Jz_yup.item()   ,\n",
    "                  \"Jz_ydown\" : Jz_ydown.item() ,\n",
    "                  \"Jz_zup\"   : Jz_zup.item()   , \n",
    "                  \"Jz_zdown\" : Jz_zdown.item() , \n",
    "                  \"JE_upstream\"  : JE_upstream.item()  ,\n",
    "                  \"JE_nose\"  : JE_nose.item()  ,\n",
    "                  \"JE_yup\"   : JE_yup.item()   ,\n",
    "                  \"JE_ydown\" : JE_ydown.item() ,\n",
    "                  \"JE_zup\"   : JE_zup.item()   , \n",
    "                  \"JE_zdown\" : JE_zdown.item() ,\n",
    "                  \"JxB_upstream\"  : JxB_upstream.item()  ,\n",
    "                  \"JxB_nose\"  : JxB_nose.item()  ,\n",
    "                  \"JxB_yup\"   : JxB_yup.item()   ,\n",
    "                  \"JxB_ydown\" : JxB_ydown.item() ,\n",
    "                  \"JxB_zup\"   : JxB_zup.item()   ,\n",
    "                  \"JxB_zdown\" : JxB_zdown.item() ,\n",
    "                  \"Pmag_upstream\"  : Pmag_upstream.item()  ,\n",
    "                  \"Pmag_nose\"  : Pmag_nose.item()  ,\n",
    "                  \"Pmag_yup\"   : Pmag_yup.item()   ,\n",
    "                  \"Pmag_ydown\" : Pmag_ydown.item() ,\n",
    "                  \"Pmag_zup\"   : Pmag_zup.item()   , \n",
    "                  \"Pmag_zdown\" : Pmag_zdown.item() ,\n",
    "                  \"Pdyn_upstream\"  : Pdyn_upstream.item()  ,\n",
    "                  \"Pdyn_nose\"  : Pdyn_nose.item()  ,\n",
    "                  \"Pdyn_yup\"   : Pdyn_yup.item()   ,\n",
    "                  \"Pdyn_ydown\" : Pdyn_ydown.item() ,\n",
    "                  \"Pdyn_zup\"   : Pdyn_zup.item()   , \n",
    "                  \"Pdyn_zdown\" : Pdyn_zdown.item(),\n",
    "                  \"Pth_upstream\"  : Pth_upstream.item()  ,\n",
    "                  \"Pth_nose\"  : Pth_nose.item()  ,\n",
    "                  \"Pth_yup\"   : Pth_yup.item()   ,\n",
    "                  \"Pth_ydown\" : Pth_ydown.item() ,\n",
    "                  \"Pth_zup\"   : Pth_zup.item()   , \n",
    "                  \"Pth_zdown\" : Pth_zdown.item() ,\n",
    "                  \"Beta_upstream\"  : Beta_upstream.item()  ,\n",
    "                  \"Beta_nose\"  : Beta_nose.item()  ,\n",
    "                  \"Beta_yup\"   : Beta_yup.item()   ,\n",
    "                  \"Beta_ydown\" : Beta_ydown.item() ,\n",
    "                  \"Beta_zup\"   : Beta_zup.item()   , \n",
    "                  \"Beta_zdown\" : Beta_zdown.item() ,\n",
    "                  \"rmsB_upstream\"  : rmsB_upstream.item()  ,\n",
    "                  \"rmsB_nose\"  : rmsB_nose.item()  ,\n",
    "                  \"rmsB_yup\"   : rmsB_yup.item()   ,\n",
    "                  \"rmsB_ydown\" : rmsB_ydown.item() ,\n",
    "                  \"rmsB_zup\"   : rmsB_zup.item()   , \n",
    "                  \"rmsB_zdown\" : rmsB_zdown.item() ,\n",
    "                  \"rmsBoB_upstream\"  : rmsBoB_upstream.item()  ,\n",
    "                  \"rmsBoB_nose\"  : rmsBoB_nose.item()  ,\n",
    "                  \"rmsBoB_yup\"   : rmsBoB_yup.item()   ,\n",
    "                  \"rmsBoB_ydown\" : rmsBoB_ydown.item() ,\n",
    "                  \"rmsBoB_zup\"   : rmsBoB_zup.item()   ,\n",
    "                  \"rmsBoB_zdown\" : rmsBoB_zdown.item()\n",
    "\n",
    "#                  , \"E + vxB\",\n",
    "#                  , \"norm(E + vxB) / norm(vxB) \"\n",
    "#                  , \"J x B\"\n",
    "#                    , \"tearing at magnetopause\"\n",
    "                \n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = { time_label : relevant_data } \n",
    "\n",
    "if path_json.exists():\n",
    "    with open(path_json, \"r\", encoding='utf-8') as story:\n",
    "        stored_data = json.load(story)\n",
    "        \n",
    "        if (type(stored_data) == dict):\n",
    "            if time_label in stored_data:\n",
    "                print(f\"Some values were already stored for this time dump {time_label}, they were updated.\")\n",
    "                stored_data[time_label].update(new_data[time_label])\n",
    "            if time_label not in stored_data:\n",
    "                print(f\"This time_dump {time_label} did not have any data yet. Values were added.\")\n",
    "                stored_data.update(new_data)\n",
    "else:\n",
    "    print(\"There was no stored data. \\n\"\n",
    "          \"A '.json' containing a dict will be created. \\n\"\n",
    "          f\"This dict will only contain the data for time t{time}.\")\n",
    "    stored_data = new_data            \n",
    "\n",
    "with open(path_json, \"w\", encoding='utf-8') as updated_story:\n",
    "    print(\"Writing new values\")\n",
    "    json.dump(stored_data, updated_story)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_json, \"r\", encoding='utf-8') as story:\n",
    "    data = json.load(story)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some small tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[f\"t{time}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdyn_upstream = data[f\"t{time}\"]['Pdyn_upstream']\n",
    "pmag_upstream = data[f\"t{time}\"]['Pmag_upstream']\n",
    "pth_upstream  = data[f\"t{time}\"]['Pth_upstream']\n",
    "\n",
    "pdyn_nose = data[f\"t{time}\"]['Pdyn_nose']\n",
    "pmag_nose = data[f\"t{time}\"]['Pmag_nose']\n",
    "pth_nose  = data[f\"t{time}\"]['Pth_nose']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"pressure in upstream solar wind  = {pdyn_upstream + pmag_upstream + pth_upstream : 0.2f} nPa, with pdyn = {pdyn_upstream:0.2f}, pth = {pth_upstream:0.2f}, pmag = {pmag_upstream:0.2f}\"\n",
    "       + '\\n' +\n",
    "      f\"pressure in magnetosheath nose   = {pdyn_nose + pmag_nose + pth_nose : 0.2f} nPa, with pdyn = {pdyn_nose:0.2f}, pth = {pth_nose:0.2f}, pmag = {pmag_nose:0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmsB_upstream, rmsB_nose,rmsB_yup,rmsB_ydown,rmsB_zup,rmsB_zdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(MD.edge, MD.size_cubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_cubes = abs(x_bow_shock-x_magnetopause) - 2*MD.edge #TODO: try other values\n",
    "        \n",
    "magnetosheath_half_width = abs(x_bow_shock-x_magnetopause)/2\n",
    "\n",
    "x_max = x_magnetopause + magnetosheath_half_width + size_cubes/2\n",
    "x_min = x_magnetopause + magnetosheath_half_width - size_cubes/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(size_cubes)\n",
    "print(magnetosheath_half_width)\n",
    "print(x_max)\n",
    "print(x_min)\n",
    "\n",
    "x_max-x_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_bow_shock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(loc)\n",
    "# print(MD.convert_coord_to_indices(loc))\n",
    "# print(x[MD.convert_coord_to_indices(loc)[0]],\n",
    "#       y[MD.convert_coord_to_indices(loc)[1]],\n",
    "#       z[MD.convert_coord_to_indices(loc)[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### R_Earth = 6400 #km\n",
    "\n",
    "print(x_bow_shock * cwp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
