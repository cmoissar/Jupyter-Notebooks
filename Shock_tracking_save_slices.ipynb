{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Module_Diagnostics.ipynb\n",
      "testing compute_RMS(...):\n",
      "This should be close to 1: 0.9691587954809632\n",
      "This should be close to 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pylab as pl\n",
    "import matplotlib\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from matplotlib.gridspec    import GridSpec\n",
    "import import_ipynb\n",
    "\n",
    "import Module_Diagnostics as MD\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "#Debugger. For some reason, using it inside a function works well. Otherwise...\n",
    "from IPython.core.debugger import set_trace\n",
    "#exemple: \n",
    "# def debug():\n",
    "#     set_trace()\n",
    "    \n",
    "#     `code_to_debug`\n",
    "    \n",
    "#     return\n",
    "\n",
    "# debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = [9.4, 4.8]\n",
    "# matplotlib.use('nbagg') #_comment this line if you don't need to interact with plots (zoom, translations, savings...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose run and time for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date of the simulation (DD_MM_YY): 18_08_20\n"
     ]
    }
   ],
   "source": [
    "run_name = 'RUN_NAME'\n",
    "\n",
    "### Only if working on lx-moissard\n",
    "Cluster = 'Occ/'\n",
    "run_name = '20_08_18_new_big_one_0'\n",
    "filepath = '/data/Lathys/Visualisation/' + Cluster + run_name + '/ncfiles/'\n",
    "### On Occ\n",
    "# filepath = '../ncfiles/'\n",
    "\n",
    "#This is used by the functions find_ip_shock(N, V) and find_mc_leading_edge(B)\n",
    "metadata = {'t_shock_entrance' : 130,\n",
    "            't_shock_exit'     : 240,\n",
    "            't_MC_entrance'    : 130,\n",
    "            't_MC_exit'        : 270}\n",
    "#todo: autodefine t_collision? maybe from story_reader will be easier, as lines will cross on the multivariate plot\n",
    "\n",
    "from_time = 210\n",
    "to_time = 235 #metadata['t_shock_exit']\n",
    "\n",
    "date = re.search('Magw_(.+?)_t', glob.glob(filepath+'Magw*_t'+ '%05d' % from_time +'.nc')[0]).group(1) \n",
    "\n",
    "print(f'date of the simulation (DD_MM_YY): {date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plt.savefig\n",
    "storing_directory = filepath + \"../shock_tracking/\"\n",
    "path_png = Path(storing_directory)\n",
    "if path_png.exists():\n",
    "    pass\n",
    "else:\n",
    "    path_png.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storing_directory_json = filepath + \"../shock_tracking/\"\n",
    "\n",
    "path_store_json = Path(storing_directory_json)\n",
    "\n",
    "if not(path_store_json.exists()):\n",
    "    os.system(f'mkdir {path_store_json}')\n",
    "\n",
    "name = \"shock_tracking_for_Article_Part_I\" + run_name + \".json\"\n",
    "path_json = Path(storing_directory_json + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data in Hsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_slices(data, Hsw):\n",
    "    \n",
    "    x = np.array(np.around(Hsw['x']))\n",
    "    y = np.array(np.around(Hsw['y']))\n",
    "    z = np.array(np.around(Hsw['z']))\n",
    "\n",
    "    nx,  ny,  nz  = len(x), len(y), len(z)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    nx0, ny0, nz0 = ( int(np.where(abs(x)==min(abs(x)))[0]),\n",
    "                      int(np.where(abs(y)==min(abs(y)))[0]), \n",
    "                      int(np.where(abs(z)==min(abs(z)))[0])  )\n",
    "    \n",
    "    result = {}\n",
    "        \n",
    "    for item in data:\n",
    "        \n",
    "        list_xy = {}\n",
    "        list_xz = {}\n",
    "        print(item)\n",
    "        \n",
    "#         list_relevant_y = [-300, -100, -95, -90, -85, -80, -75, -70, 0, 70, 75, 80, 85, 90, 95, 100, 300]\n",
    "        list_relevant_y = [0, 90, 135, 180]\n",
    "        list_iy = [np.where(y == r_y)[0][0] for r_y in list_relevant_y]\n",
    "        for iy in list_iy:\n",
    "            list_xy.update({'y = ' + str(y[iy]): [float(value) for value in ( Hsw[item][:, iy-1 , nz0]\n",
    "                                                                             +Hsw[item][:, iy   , nz0]\n",
    "                                                                             +Hsw[item][:, iy+1 , nz0] )/3] })\n",
    "            \n",
    "#         list_relevant_z = [-300, -100, -95, -90, -85, -80, -75, -70, 0, 70, 75, 80, 85, 90, 95, 100, 300]\n",
    "        list_relevant_z = [0, 80, 150, 186]\n",
    "        list_iz = [np.where(z == r_z)[0][0] for r_z in list_relevant_z]\n",
    "        for iz in list_iz:\n",
    "            list_xz.update({'z = ' + str(z[iz]): [float(value) for value in ( Hsw[item][:, ny0 , iz-1]\n",
    "                                                                             +Hsw[item][:, ny0 , iz  ]\n",
    "                                                                             +Hsw[item][:, ny0 , iz+1] )/3] })\n",
    "        \n",
    "        print(f'mean value for {item} is {1./2*(np.nanmean(list(list_xy.values())) + np.nanmean(list(list_xz.values())))}')\n",
    "        result.update({  item: { '(xy) plane': list_xy,\n",
    "                                 '(xz) plane': list_xz }  })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -633.9697616978171\n",
      "Vy\n",
      "mean value for Vy is -0.8899120135981013\n",
      "Vz\n",
      "mean value for Vz is 18.906930782630965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moissard/venv/lib/python3.6/site-packages/ipykernel_launcher.py:26: UserWarning: Warning: converting a masked element to nan.\n",
      "/home/moissard/venv/lib/python3.6/site-packages/ipykernel_launcher.py:34: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some values were already stored for this time dump 00210, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -635.0211971190126\n",
      "Vy\n",
      "mean value for Vy is -0.7946166802191966\n",
      "Vz\n",
      "mean value for Vz is 18.51292615138987\n",
      "Some values were already stored for this time dump 00211, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -636.6538012109933\n",
      "Vy\n",
      "mean value for Vy is -0.6826930166618888\n",
      "Vz\n",
      "mean value for Vz is 18.795534236984793\n",
      "Some values were already stored for this time dump 00212, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -637.8333442827332\n",
      "Vy\n",
      "mean value for Vy is -0.8162861259501153\n",
      "Vz\n",
      "mean value for Vz is 18.977371388241743\n",
      "Some values were already stored for this time dump 00213, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -639.3608331850384\n",
      "Vy\n",
      "mean value for Vy is -0.7477232424845652\n",
      "Vz\n",
      "mean value for Vz is 19.55380342007654\n",
      "Some values were already stored for this time dump 00214, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -640.7940279676734\n",
      "Vy\n",
      "mean value for Vy is -0.6206034299633637\n",
      "Vz\n",
      "mean value for Vz is 19.317739625586\n",
      "Some values were already stored for this time dump 00215, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -642.5453262687952\n",
      "Vy\n",
      "mean value for Vy is -0.37722023524557113\n",
      "Vz\n",
      "mean value for Vz is 20.044519111812498\n",
      "Some values were already stored for this time dump 00216, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -644.1941698361231\n",
      "Vy\n",
      "mean value for Vy is -1.132356865382902\n",
      "Vz\n",
      "mean value for Vz is 18.929416352533288\n",
      "Some values were already stored for this time dump 00217, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -644.827018410539\n",
      "Vy\n",
      "mean value for Vy is -0.36315840052820325\n",
      "Vz\n",
      "mean value for Vz is 19.106105851294615\n",
      "Some values were already stored for this time dump 00218, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -648.0374249971642\n",
      "Vy\n",
      "mean value for Vy is -0.8855658669549024\n",
      "Vz\n",
      "mean value for Vz is 20.14934947591538\n",
      "Some values were already stored for this time dump 00219, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/Hsw_18_08_20_t00220.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91ace2ab6818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf /tmp/* >/dev/null 2>&1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## Load Vxyz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mHsw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_data_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hsw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHsw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Lathys/Visualisation/Jupyter-Notebooks/Module_Diagnostics.ipynb\u001b[0m in \u001b[0;36mimport_data_3D\u001b[0;34m(filepath, date, time, str_file_type)\u001b[0m\n",
      "\u001b[0;32m/data/Lathys/Visualisation/read_netcdf_3D.py\u001b[0m in \u001b[0;36mreadNetcdfFile3D\u001b[0;34m(filepath, filename, str_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadNetcdfFile3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcoord_sys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Coordinate_system'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/Hsw_18_08_20_t00220.nc'"
     ]
    }
   ],
   "source": [
    "for time in range(from_time, to_time):\n",
    "    time = '%05d' % time    # Change the time to string format, needed by functions\n",
    "\n",
    "    os.system('rm -rf /tmp/* >/dev/null 2>&1')\n",
    "    ## Load Vxyz\n",
    "    Hsw = MD.import_data_3D(filepath, date, time, 'Hsw')\n",
    "  \n",
    "    x = np.array(np.around(Hsw['x']))\n",
    "    y = np.array(np.around(Hsw['y']))\n",
    "    z = np.array(np.around(Hsw['z']))\n",
    "\n",
    "    cwp = Hsw['c_omegapi']\n",
    "    gstep = Hsw['gstep']\n",
    "\n",
    "    nx,  ny,  nz  = len(x), len(y), len(z)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    nx0, ny0, nz0 = (  int(np.where(abs(x)==min(abs(x)))[0]),\n",
    "                       int(np.where(abs(y)==min(abs(y)))[0]), \n",
    "                       int(np.where(abs(z)==min(abs(z)))[0])  )\n",
    "\n",
    "      \n",
    "    new_data = {  time: collect_slices(['Vx', 'Vy', 'Vz'], Hsw), 'x': [float(xj) for xj in x],\n",
    "                                                                 'y': [float(yj) for yj in y],\n",
    "                                                                 'z': [float(zj) for zj in z]  }\n",
    "\n",
    "    if path_json.exists():\n",
    "        with open(path_json, \"r\", encoding='utf-8') as shock_tracking:\n",
    "            stored_data = json.load(shock_tracking)\n",
    "\n",
    "            if (type(stored_data) == dict):\n",
    "                if time in stored_data:\n",
    "                    print(f\"Some values were already stored for this time dump {time}, they were updated.\")\n",
    "                    stored_data[time].update(new_data[time])\n",
    "                if time not in stored_data:\n",
    "                    print(f\"This time_dump {time} did not have any data yet. Values were added.\")\n",
    "                    stored_data.update(new_data)\n",
    "    else:\n",
    "        print(\"There was no stored data. \\n\"\n",
    "              \"A '.json' containing a dict will be created. \\n\"\n",
    "              f\"This dict will only contain the data for time {time}.\")\n",
    "        stored_data = new_data            \n",
    "\n",
    "    with open(path_json, \"w\", encoding='utf-8') as updated_shock_tracking:\n",
    "        print(\"Writing new values\")\n",
    "        json.dump(stored_data, updated_shock_tracking)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_shock_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
