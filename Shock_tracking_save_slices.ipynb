{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from Module_Diagnostics.ipynb\n",
      "testing compute_RMS(...):\n",
      "This should be close to 1: 0.9640211903287403\n",
      "This should be close to 0: 0.0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pylab as pl\n",
    "import matplotlib\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib import rcParams\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "from matplotlib.gridspec    import GridSpec\n",
    "import import_ipynb\n",
    "\n",
    "import Module_Diagnostics as MD\n",
    "import numpy as np\n",
    "from tempfile import mkdtemp\n",
    "import os.path as path\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "#Debugger. For some reason, using it inside a function works well. Otherwise...\n",
    "from IPython.core.debugger import set_trace\n",
    "#exemple: \n",
    "# def debug():\n",
    "#     set_trace()\n",
    "    \n",
    "#     `code_to_debug`\n",
    "    \n",
    "#     return\n",
    "\n",
    "# debug()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "rcParams[\"figure.figsize\"] = [9.4, 4.8]\n",
    "# matplotlib.use('nbagg') #_comment this line if you don't need to interact with plots (zoom, translations, savings...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose run and time for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date of the simulation (DD_MM_YY): 18_08_20\n"
     ]
    }
   ],
   "source": [
    "run_name = 'RUN_NAME'\n",
    "\n",
    "### Only if working on lx-moissard\n",
    "Cluster = 'Occ/'\n",
    "run_name = '20_08_18_new_big_one_0'\n",
    "filepath = '/data/Lathys/Visualisation/' + Cluster + run_name + '/ncfiles/'\n",
    "### On Occ\n",
    "# filepath = '../ncfiles/'\n",
    "\n",
    "#This is used by the functions find_ip_shock(N, V) and find_mc_leading_edge(B)\n",
    "metadata = {'t_shock_entrance' : 130,\n",
    "            't_shock_exit'     : 240,\n",
    "            't_MC_entrance'    : 130,\n",
    "            't_MC_exit'        : 270}\n",
    "#todo: autodefine t_collision? maybe from story_reader will be easier, as lines will cross on the multivariate plot\n",
    "\n",
    "from_time = 210\n",
    "to_time = 235 #metadata['t_shock_exit']\n",
    "\n",
    "date = re.search('Magw_(.+?)_t', glob.glob(filepath+'Magw*_t'+ '%05d' % from_time +'.nc')[0]).group(1) \n",
    "\n",
    "print(f'date of the simulation (DD_MM_YY): {date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for plt.savefig\n",
    "storing_directory = filepath + \"../shock_tracking/\"\n",
    "path_png = Path(storing_directory)\n",
    "if path_png.exists():\n",
    "    pass\n",
    "else:\n",
    "    path_png.mkdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "storing_directory_json = filepath + \"../shock_tracking/\"\n",
    "\n",
    "path_store_json = Path(storing_directory_json)\n",
    "\n",
    "if not(path_store_json.exists()):\n",
    "    os.system(f'mkdir {path_store_json}')\n",
    "\n",
    "name = \"shock_tracking_for_Article_Part_I\" + run_name + \".json\"\n",
    "path_json = Path(storing_directory_json + name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data in Hsw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_slices(data, Hsw):\n",
    "    \n",
    "    x = np.array(np.around(Hsw['x']))\n",
    "    y = np.array(np.around(Hsw['y']))\n",
    "    z = np.array(np.around(Hsw['z']))\n",
    "\n",
    "    nx,  ny,  nz  = len(x), len(y), len(z)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    nx0, ny0, nz0 = ( int(np.where(abs(x)==min(abs(x)))[0]),\n",
    "                      int(np.where(abs(y)==min(abs(y)))[0]), \n",
    "                      int(np.where(abs(z)==min(abs(z)))[0])  )\n",
    "    \n",
    "    result = {}\n",
    "        \n",
    "    for item in data:\n",
    "        \n",
    "        list_xy = {}\n",
    "        list_xz = {}\n",
    "        print(item)\n",
    "        \n",
    "#         list_relevant_y = [-300, -100, -95, -90, -85, -80, -75, -70, 0, 70, 75, 80, 85, 90, 95, 100, 300]\n",
    "        list_relevant_y = [0, 76, 90, 300]\n",
    "        list_iy = [np.where(y == r_y)[0][0] for r_y in list_relevant_y]\n",
    "        for iy in list_iy:\n",
    "            list_xy.update({'y = ' + str(y[iy]): [float(value) for value in ( Hsw[item][:, iy-1 , nz0]\n",
    "                                                                             +Hsw[item][:, iy   , nz0]\n",
    "                                                                             +Hsw[item][:, iy+1 , nz0] )/3] })\n",
    "            \n",
    "#         list_relevant_z = [-300, -100, -95, -90, -85, -80, -75, -70, 0, 70, 75, 80, 85, 90, 95, 100, 300]\n",
    "        list_relevant_z = [0, 87, 80, 300]\n",
    "        list_iz = [np.where(z == r_z)[0][0] for r_z in list_relevant_z]\n",
    "        for iz in list_iz:\n",
    "            list_xz.update({'z = ' + str(z[iz]): [float(value) for value in ( Hsw[item][:, ny0 , iz-1]\n",
    "                                                                             +Hsw[item][:, ny0 , iz  ]\n",
    "                                                                             +Hsw[item][:, ny0 , iz+1] )/3] })\n",
    "        \n",
    "        print(f'mean value for {item} is {1./2*(np.nanmean(list(list_xy.values())) + np.nanmean(list(list_xz.values())))}')\n",
    "        result.update({  item: { '(xy) plane': list_xy,\n",
    "                                 '(xz) plane': list_xz }  })\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -631.793846604821\n",
      "Vy\n",
      "mean value for Vy is -2.2873903861569693\n",
      "Vz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moissard/venv/lib/python3.6/site-packages/ipykernel_launcher.py:25: UserWarning: Warning: converting a masked element to nan.\n",
      "/home/moissard/venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: UserWarning: Warning: converting a masked element to nan.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value for Vz is 16.999995764385453\n",
      "Some values were already stored for this time dump 00210, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n",
      "Reading Uz...\n",
      "Reading T...\n",
      "Close file and return...\n",
      "Vx\n",
      "mean value for Vx is -633.2436289230236\n",
      "Vy\n",
      "mean value for Vy is -2.2079124640571215\n",
      "Vz\n",
      "mean value for Vz is 16.682439963251245\n",
      "Some values were already stored for this time dump 00211, they were updated.\n",
      "Writing new values\n",
      "Importing Hsw 3D from /data/Lathys/Visualisation/Occ/20_08_18_new_big_one_0/ncfiles/\n",
      "Reading density...\n",
      "Reading Ux...\n",
      "Reading Uy...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.67 GiB for an array with shape (1502, 722, 662) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-91ace2ab6818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf /tmp/* >/dev/null 2>&1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m## Load Vxyz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mHsw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_data_3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Hsw'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHsw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/Lathys/Visualisation/Jupyter-Notebooks/Module_Diagnostics.ipynb\u001b[0m in \u001b[0;36mimport_data_3D\u001b[0;34m(filepath, date, time, str_file_type)\u001b[0m\n",
      "\u001b[0;32m/data/Lathys/Visualisation/Jupyter-Notebooks/read_netcdf_3D.py\u001b[0m in \u001b[0;36mreadNetcdfFile3D\u001b[0;34m(filepath, filename, str_data)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reading Uy...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mVy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Uy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mVy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mVy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   4137\u001b[0m         \u001b[0;31m# In analogy with __rsub__ and __rdiv__, use original order:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4138\u001b[0m         \u001b[0;31m# we get here from `other * self`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4141\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__div__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.6/site-packages/numpy/ma/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, a, b, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseterr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivide\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m         \u001b[0;31m# Get the mask for the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgetmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 2.67 GiB for an array with shape (1502, 722, 662) and data type float32"
     ]
    }
   ],
   "source": [
    "for time in range(from_time, to_time):\n",
    "    time = '%05d' % time    # Change the time to string format, needed by functions\n",
    "\n",
    "    os.system('rm -rf /tmp/* >/dev/null 2>&1')\n",
    "    ## Load Vxyz\n",
    "    Hsw = MD.import_data_3D(filepath, date, time, 'Hsw')\n",
    "  \n",
    "    x = np.array(np.around(Hsw['x']))\n",
    "    y = np.array(np.around(Hsw['y']))\n",
    "    z = np.array(np.around(Hsw['z']))\n",
    "\n",
    "    cwp = Hsw['c_omegapi']\n",
    "    gstep = Hsw['gstep']\n",
    "\n",
    "    nx,  ny,  nz  = len(x), len(y), len(z)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    # Location of the planet is defined in the .ncfiles as (x,y,z) = (0,0,0)\n",
    "    nx0, ny0, nz0 = (  int(np.where(abs(x)==min(abs(x)))[0]),\n",
    "                       int(np.where(abs(y)==min(abs(y)))[0]), \n",
    "                       int(np.where(abs(z)==min(abs(z)))[0])  )\n",
    "\n",
    "      \n",
    "    new_data = {  time: collect_slices(['Vx', 'Vy', 'Vz'], Hsw), 'x': [float(xj) for xj in x],\n",
    "                                                                 'y': [float(yj) for yj in y],\n",
    "                                                                 'z': [float(zj) for zj in z]  }\n",
    "\n",
    "    if path_json.exists():\n",
    "        with open(path_json, \"r\", encoding='utf-8') as shock_tracking:\n",
    "            stored_data = json.load(shock_tracking)\n",
    "\n",
    "            if (type(stored_data) == dict):\n",
    "                if time in stored_data:\n",
    "                    print(f\"Some values were already stored for this time dump {time}, they were updated.\")\n",
    "                    stored_data[time].update(new_data[time])\n",
    "                if time not in stored_data:\n",
    "                    print(f\"This time_dump {time} did not have any data yet. Values were added.\")\n",
    "                    stored_data.update(new_data)\n",
    "    else:\n",
    "        print(\"There was no stored data. \\n\"\n",
    "              \"A '.json' containing a dict will be created. \\n\"\n",
    "              f\"This dict will only contain the data for time {time}.\")\n",
    "        stored_data = new_data            \n",
    "\n",
    "    with open(path_json, \"w\", encoding='utf-8') as updated_shock_tracking:\n",
    "        print(\"Writing new values\")\n",
    "        json.dump(stored_data, updated_shock_tracking)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_shock_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
